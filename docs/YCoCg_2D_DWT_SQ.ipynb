{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://nbviewer.org/github/vicente-gonzalez-ruiz/DWT/blob/master/docs/YCoCg_2D_DWT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://badgen.net/badge/Launch/on%20Google%20Colab/blue?icon=notebook)](https://colab.research.google.com/github/vicente-gonzalez-ruiz/DWT/blob/master/docs/YCoCg_2D_DWT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Compression with YCoCg/DWT + 2D-DWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from skimage import io\n",
    "except:\n",
    "    !pip install scikit-image\n",
    "    from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pylab\n",
    "except:\n",
    "    !pip install matplotlib\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pywt\n",
    "except:\n",
    "    !pip install pywavelets\n",
    "    import pywt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ln -sf ~/repos/image_IO/logging_config.py .\n",
    "!ln -sf ~/repos/image_IO/image_3.py .\n",
    "import image_3 as RGB_image\n",
    "!ln -sf ~/repos/image_IO/image_1.py .\n",
    "import image_1 as gray_image\n",
    "!ln -sf ~/repos/DWT/color_dyadic_DWT.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import color_dyadic_DWT as DWT\n",
    "try:\n",
    "    #from DWT.color_dyadic_DWT import analyze as DWT\n",
    "    #import DWT\n",
    "    from DWT import color_dyadic_DWT as DWT\n",
    "except:\n",
    "    !pip install \"DWT @ git+https://github.com/vicente-gonzalez-ruiz/DWT\"\n",
    "    from DWT import color_dyadic_DWT as DWT\n",
    "    #import DWT\n",
    "    #from DWT.color_dyadic_DWT import analyze as DWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ln -sf ~/information_theory/information.py .\n",
    "import information\n",
    "!ln -sf ~/information_theory/distortion.py .\n",
    "import distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from information_theory.information import entropy as compute_entropy\n",
    "    from information_theory.information import energy as compute_energy                         \n",
    "    from information_theory.distortion import RMSE\n",
    "except:\n",
    "    !pip install \"information_theory @ git+https://github.com/vicente-gonzalez-ruiz/information_theory\"\n",
    "    from information_theory.information import entropy as compute_entropy\n",
    "    from information_theory.information import energy as compute_energy                         \n",
    "    from information_theory.distortion import RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!ln -sf ~/repos/YCoCg/YCoCg.py .\n",
    "#import YCoCg as YUV\n",
    "!ln -sf ~/repos/DCT/color_DCT.py .\n",
    "import color_DCT as YUV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #from color_transforms.YCoCg import from_RGB\n",
    "    #from color_transforms.YCoCg import to_RGB\n",
    "    #from color_transforms.YCoCg import name as YUV_name\n",
    "    from color_transforms import YCoCg as YUV\n",
    "except:\n",
    "    !pip install \"color_transforms @ git+https://github.com/vicente-gonzalez-ruiz/color_transforms\"\n",
    "    #from color_transforms.YCoCg import from_RGB\n",
    "    #from color_transforms.YCoCg import to_RGB\n",
    "    #from color_transforms.YCoCg import name as YUV_name\n",
    "    from color_transforms import YCoCg as YUV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ln -sf ~/repos/scalar_quantization/quantization.py .\n",
    "import quantization\n",
    "!ln -sf ~/repos/scalar_quantization/deadzone_quantization.py .\n",
    "#import deadzone_quantization as deadzone\n",
    "from deadzone_quantization import Deadzone_Quantizer as Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from scalar_quantization.deadzone_quantization import Deadzone_Quantizer as Quantizer                          \n",
    "except:\n",
    "    !pip install \"scalar_quantization @ git+https://github.com/vicente-gonzalez-ruiz/scalar_quantization\"\n",
    "    from scalar_quantization.deadzone_quantization import Deadzone_Quantizer as Quantizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOME = os.environ[\"HOME\"]\n",
    "#test_image = \"../sequences/stockholm/\"\n",
    "test_image = HOME + \"/repos/MRVC/images/lena_color/\"\n",
    "#test_image = HOME + \"/repos/MRVC/images/white/\"\n",
    "#test_image = \"../images/lena_bw/\"\n",
    "#test_image = HOME + \"/repos/MRVC/images/circle/\"\n",
    "\n",
    "#quantizer = deadzone.Deadzone_Quantizer\n",
    "\n",
    "#RGB_image.write = RGB_image.debug_write # Faster, but lower compression\n",
    "#RGB_image.write = information.write # The fastest, but returns only an estimation of the length\n",
    "#gray_image.write = gray_image.debug_write # Faster, but lower compression\n",
    "#gray_image.write = information.write # The fastest, but returns only an estimation of the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"http://www.hpca.ual.es/~vruiz/images/lena.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wavelet db5\n",
      "  Family name:    Daubechies\n",
      "  Short name:     db\n",
      "  Filters length: 10\n",
      "  Orthogonal:     True\n",
      "  Biorthogonal:   True\n",
      "  Symmetry:       asymmetric\n",
      "  DWT:            True\n",
      "  CWT:            False\n"
     ]
    }
   ],
   "source": [
    "#wavelet_name = \"Haar\"\n",
    "#wavelet_name = \"db3\"\n",
    "wavelet_name = \"db5\"\n",
    "#wavelet_name = \"db7\"\n",
    "#wavelet_name = \"db15\"\n",
    "#wavelet_name = \"bior3.1\"\n",
    "#wavelet_name = \"bior3.3\"\n",
    "#wavelet_name = \"bior5.5\"\n",
    "wavelet = pywt.Wavelet(wavelet_name)\n",
    "print(wavelet)\n",
    "N_levels = 5\n",
    "N_components = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subband-components information\n",
    "Information about the coefficients after using a color transform and the DWT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(sbc):\n",
    "    max = sbc.max()\n",
    "    min = sbc.min()\n",
    "    max_min = max - min\n",
    "    if max_min > 0:\n",
    "        log2_max_min = math.ceil(math.log(max_min)/math.log(2))\n",
    "    else:\n",
    "        log2_max_min = 0\n",
    "    avg = np.average(sbc)\n",
    "    dev = math.sqrt(np.var(sbc))\n",
    "    entropy = compute_entropy(sbc.flatten().astype(np.int16))\n",
    "    energy = compute_energy(sbc)\n",
    "    avg_energy = compute_energy(sbc)/sbc.size\n",
    "    shape = sbc.shape\n",
    "    return max, min, max_min, log2_max_min, avg, dev, entropy, energy, avg_energy, shape\n",
    "\n",
    "def subbands_info(decomp):\n",
    "    print(\"sorting subband-components by entropy\")\n",
    "    print(\"sbc maximum mininum    max-min average std-dev entropy        energy  avg-enegy shape\")\n",
    "    list_of_subbands_components = []\n",
    "    sbc_index = 0\n",
    "    accumulated_entropy = 0\n",
    "    max_val = 0\n",
    "    min_val = 10E10\n",
    "    for c in range(N_components):\n",
    "        sbc = decomp[0][..., c]\n",
    "        infos = info(sbc)\n",
    "        list_of_subbands_components.append((sbc_index, *infos))\n",
    "        entropy = infos[5]\n",
    "        accumulated_entropy += (entropy * sbc.size)\n",
    "        if max_val < infos[0]:\n",
    "            max_val = infos[0]\n",
    "        if min_val > infos[1]:\n",
    "            min_val = infos[1]\n",
    "        sbc_index += 1\n",
    "    for sr in decomp[1:]:\n",
    "        for sb in sr:\n",
    "            for c in range(N_components):\n",
    "                sbc = sb[..., c]\n",
    "                infos = info(sbc)\n",
    "                list_of_subbands_components.append((sbc_index, *infos))\n",
    "                entropy = infos[5]\n",
    "                accumulated_entropy += (entropy * sbc.size)\n",
    "                if max_val < infos[0]:\n",
    "                    max_val = infos[0]\n",
    "                if min_val > infos[1]:\n",
    "                    min_val = infos[1]\n",
    "                sbc_index += 1\n",
    "    sorted_list_of_subbands_components = sorted(list_of_subbands_components, key=lambda x: x[6])[::-1]\n",
    "    for _i in sorted_list_of_subbands_components:\n",
    "        sbc_index, max, min, max_min, log2_max_min, avg, dev, entropy, energy, avg_energy, shape = _i\n",
    "        print(f\"{sbc_index:3d} {max:7.1f} {min:7.1f} {max_min:7.1f} {log2_max_min:>2d} {avg:7.1f} {dev:7.1f} {entropy:7.1f} {energy:13.1f} {avg_energy:10.1f} {shape}\")\n",
    "\n",
    "    avg_entropy = accumulated_entropy / img.size\n",
    "    print(\"Image path:\", fn)\n",
    "    print(\"Wavelet name:\", wavelet)\n",
    "    print(\"Number of levels:\", N_levels)\n",
    "    print(\"Number of subbands:\", int((sbc_index+1)/3))\n",
    "    print(\"Number of subband-components:\", sbc_index+1)\n",
    "    print(\"Average entropy in the wavelet domain:\", avg_entropy)\n",
    "    print(\"Entropy in the image domain:\", compute_entropy(img.flatten().astype(np.uint8)))\n",
    "    print(\"Maximum coefficient value:\", max_val)\n",
    "    print(\"Minimum coefficient value:\", min_val)\n",
    "    print(\"Dynamic range in the transform domain:\", max_val - min_val)\n",
    "    print(\"Number of bits required for encoding the coefficients using integer numbers:\", math.ceil(math.log(max_val - min_val)/math.log(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wavelet db5\n",
      "  Family name:    Daubechies\n",
      "  Short name:     db\n",
      "  Filters length: 10\n",
      "  Orthogonal:     True\n",
      "  Biorthogonal:   True\n",
      "  Symmetry:       asymmetric\n",
      "  DWT:            True\n",
      "  CWT:            False\n",
      "luma avg=120.56250381469727\n",
      "sorting subband-components by entropy\n",
      "sbc maximum mininum    max-min average std-dev entropy        energy  avg-enegy shape\n",
      "  2    87.3  -174.6   261.9  9   -53.7    72.2     6.8     2105419.5     8097.8 (260,)\n",
      "  1    90.5  -175.0   265.6  9   -53.1    70.4     6.8     2021365.3     7774.5 (260,)\n",
      "  0    88.2  -175.8   264.1  9   -52.0    68.4     6.9     1917835.6     7376.3 (260,)\n",
      "  8     8.6   -28.2    36.7  6    -0.1     3.4     3.4        3060.1       11.8 (260,)\n",
      "  4     8.5   -11.0    19.5  5     0.1     3.0     3.4        2413.9        9.3 (260,)\n",
      "  3    10.0   -10.8    20.8  5    -0.2     3.0     3.2        2333.5        9.0 (260,)\n",
      " 11     7.0    -7.4    14.4  4    -0.0     2.6     3.1        1735.8        6.7 (260,)\n",
      "  5     6.8    -8.6    15.4  4    -0.1     2.5     3.0        1579.3        6.1 (260,)\n",
      "  7    10.1    -5.8    15.9  4     0.3     2.2     2.7        1271.1        4.9 (260,)\n",
      " 10     4.9    -6.2    11.1  4    -0.1     1.8     2.4         845.6        3.3 (260,)\n",
      "  6     3.1    -2.7     5.7  3     0.1     0.9     1.3         225.3        0.9 (260,)\n",
      "  9     2.3    -2.2     4.5  3    -0.0     0.8     0.9         155.8        0.6 (260,)\n",
      "Image path: http://www.hpca.ual.es/~vruiz/images/lena.png\n",
      "Wavelet name: Wavelet db5\n",
      "  Family name:    Daubechies\n",
      "  Short name:     db\n",
      "  Filters length: 10\n",
      "  Orthogonal:     True\n",
      "  Biorthogonal:   True\n",
      "  Symmetry:       asymmetric\n",
      "  DWT:            True\n",
      "  CWT:            False\n",
      "Number of levels: 5\n",
      "Number of subbands: 3\n",
      "Number of subband-components: 10\n",
      "Average entropy in the wavelet domain: 0.07643607973187112\n",
      "Entropy in the image domain: 7.750338980525236\n",
      "Maximum coefficient value: 90.54654881925781\n",
      "Minimum coefficient value: -175.83698787854377\n",
      "Dynamic range in the transform domain: 266.38353669780156\n",
      "Number of bits required for encoding the coefficients using integer numbers: 9\n"
     ]
    }
   ],
   "source": [
    "#N_components = 3\n",
    "#wavelet_name = \"Haar\"\n",
    "#wavelet_name = \"db3\"\n",
    "_wavelet_name = \"db5\"\n",
    "#wavelet_name = \"db7\"\n",
    "#wavelet_name = \"db15\"\n",
    "#wavelet_name = \"bior3.1\"\n",
    "#wavelet_name = \"bior3.3\"\n",
    "#wavelet_name = \"bior5.5\"\n",
    "_wavelet = pywt.Wavelet(wavelet_name)\n",
    "print(_wavelet)\n",
    "_N_levels = 1\n",
    "\n",
    "#img = RGB_image.read(test_image).astype(np.int16)\n",
    "img = io.imread(fn).astype(np.int16)\n",
    "#YUV_img = YUV.from_RGB(img)\n",
    "YUV_img = from_RGB(img)\n",
    "Y = YUV_img[..., 0]\n",
    "Y_avg = np.average(Y)\n",
    "print(f\"luma avg={Y_avg}\")\n",
    "Y -= int(Y_avg)\n",
    "decom = pywt.wavedec2(data=Y, wavelet=_wavelet, level=_N_levels)\n",
    "subbands_info(decom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "1. Most of the energy (and entropy, i.e., information) is concentrated in the low-frequency subbands.\n",
    "2. The wavelet domain is potentially more compressible than the image domain, because the entropy is smaller.\n",
    "3. The number of bits required for representing the low-frequency subbands is significantly higher than the original 8-bits/component. This number depends on the wavelet filters, the number of levels of the transform, and the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Lossless\" compression\n",
    "Notice that, since the color and spatial transforms use ploating-point arithmetic, it is impossible to guarantee the full reversibility of the encoding system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the \"glued\" representation\n",
    "In the glued mode, all the coefficients are written in a single entropy coded file. Notice that we are using 16 bits/coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossless_glued(img, YUV, wavelet, N_levels):\n",
    "    if YUV.name == \"YCoCg\":\n",
    "        img = img.astype(np.int16)\n",
    "    YUV_img = YUV.from_RGB(img)\n",
    "    avgs = [np.average(YUV_img[...,c]) for c in range(3)]\n",
    "    logger.info(f\"avgs={avgs}\")\n",
    "    for c in range(3):\n",
    "        YUV_img[..., c] -= int(avgs[c])\n",
    "    decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "    decom_ = DWT.add(decom, 32768)\n",
    "    decom__ = DWT.set_type(decom_, np.uint16)\n",
    "    output_len, slices = DWT.write_glued(decom__, \"/tmp/lossless\", 0)\n",
    "    \n",
    "    # Now we decompress the image to compute the RMSE\n",
    "    _decom = DWT.read_glued(slices, \"/tmp/lossless\", 0)\n",
    "    _decom2 = DWT.add(_decom, -32768)\n",
    "    _YUV_img = DWT.synthesize(_decom2, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        _YUV_img[..., c] += int(avgs[c])\n",
    "    _img = (YUV.to_RGB(_YUV_img)).astype(np.uint8)\n",
    "    _RMSE = distortion.RMSE(img, _img)\n",
    "    return output_len, _RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'DWT.color_dyadic_DWT' has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlossless_glued\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYUV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwavelet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_levels\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn [25], line 10\u001b[0m, in \u001b[0;36mlossless_glued\u001b[0;34m(img, YUV, wavelet, N_levels)\u001b[0m\n\u001b[1;32m      8\u001b[0m     YUV_img[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, c] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(avgs[c])\n\u001b[1;32m      9\u001b[0m decom \u001b[38;5;241m=\u001b[39m DWT\u001b[38;5;241m.\u001b[39manalyze(YUV_img, wavelet, N_levels)\n\u001b[0;32m---> 10\u001b[0m decom_ \u001b[38;5;241m=\u001b[39m \u001b[43mDWT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m(decom, \u001b[38;5;241m32768\u001b[39m)\n\u001b[1;32m     11\u001b[0m decom__ \u001b[38;5;241m=\u001b[39m DWT\u001b[38;5;241m.\u001b[39mset_type(decom_, np\u001b[38;5;241m.\u001b[39muint16)\n\u001b[1;32m     12\u001b[0m output_len, slices \u001b[38;5;241m=\u001b[39m DWT\u001b[38;5;241m.\u001b[39mwrite_glued(decom__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/lossless\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'DWT.color_dyadic_DWT' has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "print(lossless_glued(img, YUV, wavelet, N_levels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the \"unglued\" representation\n",
    "In this case, depending on the subband, we will use 8 or 16 bits/coefficient in the subband-components. Notice that \"empty\" subbands are not encoded (although without quantization, this is quite unlikely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drange(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "def add_offset(x):\n",
    "    if drange(x) < 256:\n",
    "        x = (x + 128).astype(np.uint8)\n",
    "    else:\n",
    "        x = (x + 32768).astype(np.uint16)\n",
    "    return x\n",
    "\n",
    "def sub_offset(x):\n",
    "    if drange(x) < 256:\n",
    "        x = x.astype(np.float64) - 128\n",
    "    else:\n",
    "        x = x.astype(np.float64) - 32768\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossless_unglued(img, YUV, wavelet, N_levels):\n",
    "    if YUV.name == \"YCoCg\":\n",
    "        img = img.astype(np.int16)\n",
    "    YUV_img = YUV.from_RGB(img)\n",
    "    avgs = [np.average(YUV_img[...,c]) for c in range(3)]\n",
    "    logger.info(f\"avgs={avgs}\")\n",
    "    for c in range(3):\n",
    "        YUV_img[..., c] -= int(avgs[c])\n",
    "    decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "    always_positive_decom = [add_offset(decom[0])] # always_positive_decom is PNG friendly\n",
    "    for sr in decom[1:]: # sr = spatial_resolution\n",
    "        always_positive_sr = []\n",
    "        for sb in sr: # sb = subband\n",
    "            always_positive_sr.append(add_offset(sb))\n",
    "        always_positive_decom.append(tuple(always_positive_sr))\n",
    "    output_len, slices = DWT.write_unglued(always_positive_decom, \"/tmp/lossless\", 0)\n",
    "\n",
    "    # Now we decompress the image to compute the RMSE\n",
    "    _decom = [sub_offset(always_positive_decom[0])]\n",
    "    for always_positive_sr in always_positive_decom[1:]:\n",
    "        sr = []\n",
    "        for always_positive_sb in always_positive_sr:\n",
    "            sr.append(sub_offset(always_positive_sb))\n",
    "        _decom.append(tuple(sr))\n",
    "    _YUV_img = DWT.synthesize(_decom, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        _YUV_img[..., c] += int(avgs[c])\n",
    "    _img = YUV.to_RGB(_YUV_img).astype(np.uint8)\n",
    "    _RMSE = distortion.RMSE(img, _img)\n",
    "    return output_len, _RMSE\n",
    "\n",
    "print(lossless_unglued(img, YUV, wavelet, N_levels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"unglued\" representation is more efficient. This is probably due to the \"reset\" of context that occurs when we compress each subband in a different codestream.\n",
    "\n",
    "Notice also that, in the case of \"lena\", JPEG2000 outputs 446411 bytes, and it is true lossless. This basically means that the entropy encoding algorithm used in JPEG2000 compress more than PNG. This probably happens because we are not exploiting the correlation between subbands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the DWT (RGB) domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom = DWT.analyze(img, wavelet, 3)\n",
    "glued_decom, shapes = DWT.glue_color_decomposition(decom)\n",
    "RGB_image.show_normalized(glued_decom, \"Glued decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalize(sb):\n",
    "    return (sb - sb.min()) / (sb.max() - sb.min())\n",
    "\n",
    "decom = DWT.analyze(img, wavelet, 3)\n",
    "view_LL = normalize(decom[0])\n",
    "view_decom = [view_LL]\n",
    "RGB_image.show(view_LL, '')\n",
    "for sr in decom[1:]:\n",
    "    view_sr = []\n",
    "    for sb in sr:\n",
    "        view_sb = normalize(sb)\n",
    "        view_sr.append(view_sb)\n",
    "        RGB_image.show(view_sb, '')\n",
    "    view_decom.append(tuple(view_sr))\n",
    "glued_decom, shapes = DWT.glue_color_decomposition(view_decom)\n",
    "RGB_image.show(glued_decom, \"Glued decomposition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD performance\n",
    "\n",
    "All subbands are quantized with the same quantization step. Notice that all subbands should have the same gain, and obviously, the transforms must be orthogonal. The distortion is measured in the image domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subband gains\n",
    "\n",
    "Not all wavelet filters have the same gain in all the subbands. The gain $G_b$ of a subband $b$ can be computed as the squared norm of the DWT synthesis basis vector of the corresponding subband (see Page 438, Chapter 10, JPEG2000 Image Compression Fundamentals, Standards and Practice). For the subband $b$, such quantity is the energy (sum of squared sample values) in an image reconstructed from exactly one unit amplitude sample in $b$ (i.e., setting all other samples in $b$ and all samples in all other subbands to 0).\n",
    "\n",
    "$G_b$ is identical for all samples in subband $b$ which are located sufficiently far from the image boundaries to not be affected by any symmetric extension procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"img_shape\" parameter should be large enough to avoid\n",
    "# any interference caused by the extension procedure.\n",
    "def compute_normalized_gains(img_shape, wavelet, N_levels):\n",
    "    gains = []\n",
    "    x = np.zeros(shape=img_shape)\n",
    "    decom = DWT.analyze(x, wavelet, N_levels)\n",
    "    decom[0][decom[0].shape[0]//2, decom[0].shape[1]//2] = 1\n",
    "    #decom[0][...] = 1\n",
    "    z = DWT.synthesize(decom, wavelet, N_levels)\n",
    "    gains.append(information.energy(z))\n",
    "    prev_sb = decom[0]\n",
    "    for sr in decom[1:]:\n",
    "        for sb in sr:\n",
    "            prev_sb[...] = 0\n",
    "            #sb[...] = 1#coeff_value/sb.size\n",
    "            sb[sb.shape[0]//2, sb.shape[1]//2] = 1\n",
    "            z = DWT.synthesize(decom, wavelet, N_levels)\n",
    "            gains.append(information.energy(z))\n",
    "            prev_sb = sb\n",
    "    \n",
    "    return gains/sum(gains)\n",
    "\n",
    "_wavelet_name = \"db5\"\n",
    "#_wavelet_name = \"bior3.5\"\n",
    "#_wavelet_name = \"bior5.5\"\n",
    "_wavelet = pywt.Wavelet(_wavelet_name)\n",
    "gains = compute_normalized_gains(img.shape, _wavelet, N_levels)\n",
    "print(gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization step sizes\n",
    "\n",
    "The gain $G_b$ of a subband $b$ should be considered in the quantization process because to minimize the quantization error (in terms of the MSE), those coefficients with a higher gain (that on average are going to have a larger dynamic range) should be quantized proportionally using\n",
    "\\begin{equation}\n",
    "  \\Delta_b = \\Delta\\sqrt{\\frac{G_0}{G_b}}\n",
    "\\end{equation}\n",
    "where $\\Delta$ is a \"base step size\", $G_b$ is the squared norm of the synthesis filter for the subband $b$, and $\\Delta_b$ is que quantization step size that should be applied to the subband $b$ (see Eq. (10.23), Chapter 10, JPEG2000 Image Compression Fundamentals, Standards and Practice). $G_0$ should be the subband gain of the LL subband.Ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = compute_normalized_gains(img.shape, wavelet, N_levels)\n",
    "print(gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q_factors = [1/math.sqrt(i) for i in gains]\n",
    "#print(Q_factors)\n",
    "#Q_factors = [math.sqrt(i/gains[0]) for i in gains]\n",
    "#print(Q_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use uniform quantization and write_unglued()\n",
    "#Q_steps = [32, 16, 8, 4, 2, 1, 1/2, 1/4, 1/8, 1/16, 1/32]\n",
    "#c = 0\n",
    "#for s in Q_steps:\n",
    "#    Q_steps[c] *= 64\n",
    "#    c += 1\n",
    "Q_steps = [256, 128, 64, 32, 16, 8]\n",
    "#Q_steps = [512, 256, 128, 64, 32, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BPP(img, decom, Q_step, Q_factors, wavelet, N_levels, write):\n",
    "    Q = Quantizer(Q_step=Q_step*Q_factors[0])\n",
    "    LL = decom[0]\n",
    "    LL_k = Q.quantize(LL)\n",
    "    LL_dQ = Q.dequantize(LL_k)\n",
    "    decom_k = [add_offset(LL_k)]\n",
    "    decom_dQ = [LL_dQ]\n",
    "    sbc_counter = 1\n",
    "    print(Q_step, Q_factors[0])\n",
    "    print(\"sb_Q_factor =\", Q_step*Q_factors[0], end=' ')\n",
    "    for sr in decom[1:]:\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr: # sb = subband\n",
    "            sb_Q_factor = Q_step*Q_factors[sbc_counter]\n",
    "            print(sb_Q_factor, end=' ')\n",
    "            Q = Quantizer(Q_step=sb_Q_factor)\n",
    "            sb_k = Q.quantize(sb)\n",
    "            sb_dQ = Q.dequantize(sb_k)\n",
    "            sr_k.append(add_offset(sb_k))\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            sbc_counter += 1\n",
    "        decom_k.append(tuple(sr_k))\n",
    "        decom_dQ.append(tuple(sr_dQ))\n",
    "    print()\n",
    "    BPP = (write(decom_k, f\"/tmp/{Q_step}_\", 0)[0]*8)/(YUV_img.shape[0]*YUV_img.shape[1])\n",
    "    return BPP, decom_dQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RD_curve(img, YUV, wavelet, N_levels, Q_factors, Q_steps, write):\n",
    "    print(\"Q_steps =\", Q_steps)\n",
    "    print(\"Q_factors =\", Q_factors)\n",
    "    YUV_img = YUV.from_RGB(img)\n",
    "    avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "    print(f\"avgs={avgs}\")\n",
    "    for c in range(3):\n",
    "        YUV_img[..., c] -= int(avgs[c])\n",
    "    decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "    RD_curve = []\n",
    "    for Q_step in Q_steps:\n",
    "        BPP, decom_dQ = get_BPP(img, decom, Q_step, Q_factors, wavelet, N_levels, write)\n",
    "        YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "        for c in range(3):\n",
    "            YUV_img_dQ[..., c] += int(avgs[c])\n",
    "        img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "        img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "        RMSE = distortion.RMSE(img, img_dQ)\n",
    "        print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "        #RGB_image.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")\n",
    "        RD_curve.append((BPP, RMSE))\n",
    "    return RD_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the glued representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q_factors = [1]*(N_levels*3+1)\n",
    "img = RGB_image.read(test_image).astype(np.int16)\n",
    "DWT_constantQ_glued = compute_RD_curve(img, YUV, wavelet, N_levels, Q_factors, Q_steps, DWT.write_glued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q_factors = [math.sqrt(gains[0]/i) for i in gains]\n",
    "img = RGB_image.read(test_image).astype(np.int16)\n",
    "DWT_factorsQ_glued = compute_RD_curve(img, YUV, wavelet, N_levels, Q_factors, Q_steps, DWT.write_glued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_constantQ_glued), label=f\"Constant Q_step\")\n",
    "pylab.plot(*zip(*DWT_factorsQ_glued), label=f\"Using factors\")\n",
    "#pylab.plot(*zip(*image_domain_DWT_RD_points2), label=f\"DWT uniform Q (image domain)\")\n",
    "#pylab.plot(*zip(*transform_domain_DWT_RD_points), label=f\"DWT uniform Q (transform domain)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of using biorthogonal transforms, the use of the subband gains improves slighly the RD performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the unglued representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_factors = [1]*(N_levels*3+1)\n",
    "img = RGB_image.read(test_image).astype(np.int16)\n",
    "DWT_constantQ_unglued = compute_RD_curve(img, YUV, wavelet, N_levels, Q_factors, Q_steps, DWT.write_unglued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_factors = [math.sqrt(gains[0]/i) for i in gains]\n",
    "img = RGB_image.read(test_image).astype(np.int16)\n",
    "DWT_factorsQ_unglued = compute_RD_curve(img, YUV, wavelet, N_levels, Q_factors, Q_steps, DWT.write_unglued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_constantQ_unglued), label=f\"Constant Q_step\")\n",
    "pylab.plot(*zip(*DWT_factorsQ_unglued), label=f\"Using factors\")\n",
    "#pylab.plot(*zip(*image_domain_DWT_RD_points2), label=f\"DWT uniform Q (image domain)\")\n",
    "#pylab.plot(*zip(*transform_domain_DWT_RD_points), label=f\"DWT uniform Q (transform domain)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if we use biorthogonal transforms, the use of the subband gains improves slighly the RD performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_factorsQ_glued), label=f\"glued\")\n",
    "pylab.plot(*zip(*DWT_factorsQ_unglued), label=f\"unglued\")\n",
    "#pylab.plot(*zip(*image_domain_DWT_RD_points2), label=f\"DWT uniform Q (image domain)\")\n",
    "#pylab.plot(*zip(*transform_domain_DWT_RD_points), label=f\"DWT uniform Q (transform domain)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writting each subband in a separate file (unglued) is more efficient than generating a single file (glued)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using only 8 bits/coefficient\n",
    "The kernels used in the DWT expand the dynamic range of the image (the coefficients need more bits to be represented). One way to ensure that we will need only 8 bits/coefficient (probably increasing the R performance of the entropy codec) is to \"pre-quantize\" the coefficients, using, for example, the following quantization pattern (example for 3 levels):\n",
    "\n",
    "    +---+---+-------+---------------+\n",
    "    | 8 | 4 |       |               |\n",
    "    +---+---+   2   |               |\n",
    "    | 4 | 4 |       |               |\n",
    "    +---+---+-------+       1       |\n",
    "    |       |       |               |\n",
    "    |   2   |   2   |               |\n",
    "    |       |       |               |\n",
    "    +-------+-------+---------------+\n",
    "    |               |               |\n",
    "    |               |               |\n",
    "    |               |               |\n",
    "    |       1       |       1       |\n",
    "    |               |               |\n",
    "    |               |               |\n",
    "    |               |               |\n",
    "    +---------------+---------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q_steps = [256, 128, 64, 32, 16, 8]\n",
    "#Q_steps = range(256, 16, -4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the 8<->16 bits/coefficient converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_8bits(decomposition): # compact?\n",
    "    '''Remove the least significant bit-planes of the <decomposition> to represent each coefficient with 8 bits.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    decomposition: list\n",
    "        The decomposition to quantize.\n",
    "        \n",
    "    Returns:\n",
    "    decomposition: list\n",
    "        The quantized decomposition.\n",
    "    \n",
    "    '''\n",
    "    N_levels = len(decomposition) - 1\n",
    "    #new_decomp = [(decomposition[0].astype(np.int16) >> N_levels).astype(np.uint8)]\n",
    "    new_decomp = [(decomposition[0].astype(np.int16) >> N_levels)]\n",
    "    levels_counter = N_levels - 1\n",
    "    for resolution in decomposition[1:]:\n",
    "        new_resol = []\n",
    "        for subband in resolution:\n",
    "            #new_resol.append((subband.astype(np.int16) >> levels_counter).astype(np.uint8))\n",
    "            new_resol.append((subband.astype(np.int16) >> levels_counter))\n",
    "        new_decomp.append(tuple(new_resol))\n",
    "        levels_counter -= 1\n",
    "    #print(\"to_8bits:\", new_decomp[0].dtype)\n",
    "    return new_decomp\n",
    "\n",
    "def to_16bits(decomposition): # uncompact ?\n",
    "    N_levels = len(decomposition) - 1\n",
    "    new_decomp = [decomposition[0].astype(np.int16) << N_levels]\n",
    "    levels_counter = N_levels - 1\n",
    "    for resolution in decomposition[1:]:\n",
    "        new_resol = []\n",
    "        for subband in resolution:\n",
    "            new_resol.append(subband.astype(np.int16) << levels_counter)\n",
    "        new_decomp.append(tuple(new_resol))\n",
    "        levels_counter -= 1\n",
    "    return new_decomp\n",
    "\n",
    "img = RGB_image.read(test_image)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[...,c]) for c in range(3)]\n",
    "#print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "#decom_8bit = to_8bits(decom)\n",
    "decom = to_8bits(decom)\n",
    "#print(decom_8bit[0].dtype)\n",
    "#print(decom[0].dtype)\n",
    "#glued_decom_8bit, shapes = DWT.glue_color_decomposition(decom_8bit)\n",
    "glued_decom, shapes = DWT.glue_color_decomposition(decom)\n",
    "#image_3.show(image_3.normalize(glued_decom_8bit))\n",
    "#image_3.show((glued_decom_8bit + 128).astype(np.uint8), \"128-shifted glued decomposition\")\n",
    "RGB_image.show((glued_decom + 128).astype(np.uint8), \"glued decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decom_dQ = to_16bits(decom_8bit)\n",
    "decom = to_16bits(decom)\n",
    "#YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "YUV_img_dQ = DWT.synthesize(decom, wavelet, N_levels)\n",
    "for c in range(3):\n",
    "    YUV_img_dQ[..., c] += int(avgs[c])\n",
    "img_dQ = (YUV.to_RGB(YUV_img_dQ)).astype(np.uint8)\n",
    "RGB_image.show(img_dQ, \"8-bit quantized and dequantized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = img.astype(np.int16) - img_dQ\n",
    "print(e.dtype, e.max(), e.min())\n",
    "plt.hist(e[...,0].ravel(), bins=256)\n",
    "plt.xlabel(\"Error value\")\n",
    "plt.ylabel(\"Ocurrences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB_image.show(RGB_image.normalize(e), \"Normalized error\")\n",
    "RGB_image.show((e + 128).astype(np.uint8), \"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbands_info(to_8bits(decom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD performance using at most 8-bits/coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the glued representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Q_step(Q_step, level):\n",
    "    #step = int(math.ceil(Q_step * math.pow(2, N_levels)))\n",
    "    step_for_8b = int(math.ceil(Q_step / math.pow(2, level)))\n",
    "    print(f\"compute_Q_step: Q_step={Q_step} level={level + 1} step_for_8b={step_for_8b}\")\n",
    "    return step_for_8b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img = RGB_image.read(test_image)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "DWT_8b_constantQ_glued = []\n",
    "for Q_step in Q_steps:\n",
    "    decom_8b = to_8bits(decom)\n",
    "    LL_8b = decom_8b[0]\n",
    "    _Q_step = compute_Q_step(Q_step, N_levels)\n",
    "    Q = Quantizer(Q_step=_Q_step)\n",
    "    LL_8b_k = Q.quantize(LL_8b) # Baybe bettter Q.get_indexes()\n",
    "    decom_8b_k = [(LL_8b_k + 128).astype(np.uint8)]\n",
    "    LL_8b_dQ = Q.dequantize(LL_8b_k) # Q.get_signal()\n",
    "    decom_8b_dQ = [LL_8b_dQ]\n",
    "    sbc_counter = 0\n",
    "    level = N_levels - 1\n",
    "    for sr_8b in decom_8b[1:]: # sr = spatial_resolution\n",
    "        sr_8b_k = []\n",
    "        sr_8b_dQ = []\n",
    "        for sb_8b in sr_8b: # sb = subband\n",
    "            _Q_step = compute_Q_step(Q_step, level)\n",
    "            Q = Quantizer(Q_step=_Q_step)\n",
    "            sb_8b_k = Q.quantize(sb_8b)\n",
    "            sb_8b_dQ = Q.dequantize(sb_8b_k)\n",
    "            sr_8b_k.append((sb_8b_k + 128).astype(np.uint8))\n",
    "            sr_8b_dQ.append(sb_8b_dQ)\n",
    "            sbc_counter += 1\n",
    "        decom_8b_k.append(tuple(sr_8b_k))\n",
    "        decom_8b_dQ.append(tuple(sr_8b_dQ))\n",
    "        level -= 1\n",
    "    BPP = (DWT.write_glued(decom_8b_k, f\"/tmp/constant_{Q_step}_\", 0)[0]*8)/(YUV_img.shape[0]*YUV_img.shape[1])\n",
    "    decom_dQ = to_16bits(decom_8b_dQ)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "    img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "    DWT_8b_constantQ_glued.append((BPP, RMSE))\n",
    "    #RGB_image.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the unglued representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img = RGB_image.read(test_image)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "DWT_8b_constantQ_unglued = []\n",
    "for Q_step in Q_steps:\n",
    "    decom_8b = to_8bits(decom)\n",
    "    LL_8b = decom_8b[0]\n",
    "    _Q_step = compute_Q_step(Q_step, N_levels)\n",
    "    Q = Quantizer(Q_step=_Q_step)\n",
    "    LL_8b_k = Q.quantize(LL_8b) # Baybe bettter Q.get_indexes()\n",
    "    decom_8b_k = [(LL_8b_k + 128).astype(np.uint8)]\n",
    "    LL_8b_dQ = Q.dequantize(LL_8b_k) # Q.get_signal()\n",
    "    decom_8b_dQ = [LL_8b_dQ]\n",
    "    sbc_counter = 0\n",
    "    level = N_levels - 1\n",
    "    for sr_8b in decom_8b[1:]: # sr = spatial_resolution\n",
    "        sr_8b_k = []\n",
    "        sr_8b_dQ = []\n",
    "        for sb_8b in sr_8b: # sb = subband\n",
    "            _Q_step = compute_Q_step(Q_step, level)\n",
    "            Q = Quantizer(Q_step=_Q_step)\n",
    "            sb_8b_k = Q.quantize(sb_8b)\n",
    "            sb_8b_dQ = Q.dequantize(sb_8b_k)\n",
    "            sr_8b_k.append((sb_8b_k + 128).astype(np.uint8))\n",
    "            sr_8b_dQ.append(sb_8b_dQ)\n",
    "            sbc_counter += 1\n",
    "        decom_8b_k.append(tuple(sr_8b_k))\n",
    "        decom_8b_dQ.append(tuple(sr_8b_dQ))\n",
    "        level -= 1\n",
    "    BPP = (DWT.write_unglued(decom_8b_k, f\"/tmp/constant_{Q_step}_\", 0)[0]*8)/(YUV_img.shape[0]*YUV_img.shape[1])\n",
    "    decom_dQ = to_16bits(decom_8b_dQ)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "    img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "    DWT_8b_constantQ_unglued.append((BPP, RMSE))\n",
    "    #RGB_image.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RD_point_8b(img, decom_8b, Q_step, Q_factors, wavelet, N_levels, write):\n",
    "    decom_8b = to_8bits(decom)\n",
    "    LL_8b = decom_8b[0]\n",
    "    _Q_step = compute_Q_step(Q_step, N_levels)\n",
    "    Q = Quantizer(Q_step=_Q_step*Q_factors[0])\n",
    "    LL_8b_k = Q.quantize(LL_8b)\n",
    "    decom_8b_k = [(LL_8b_k + 128).astype(np.uint8)]\n",
    "    LL_8b_dQ = Q.dequantize(LL_8b_k)\n",
    "    decom_8b_dQ = [LL_8b_dQ]\n",
    "    sbc_counter = 1\n",
    "    print(Q_step, Q_factors[0])\n",
    "    print(\"sb_Q_factor =\", Q_step*Q_factors[0], end=' ')\n",
    "    level = N_levels - 1\n",
    "    for sr_8b in decom_8b[1:]:\n",
    "        sr_8b_k = []\n",
    "        sr_8b_dQ = []\n",
    "        for sb_8b in sr_8b:\n",
    "            _Q_step = compute_Q_step(Q_step, level)\n",
    "            sb_Q_factor = _Q_step*Q_factors[sbc_counter]\n",
    "            print(sb_Q_factor, end=' ')\n",
    "            Q = Quantizer(Q_step=sb_Q_factor)\n",
    "            sb_8b_k = Q.quantize(sb_8b)\n",
    "            sb_8b_dQ = Q.dequantize(sb_8b_k)\n",
    "            sr_8b_k.append((sb_8b_k + 128).astype(np.uint8))\n",
    "            sr_8b_dQ.append(sb_8b_dQ)\n",
    "            sbc_counter += 1\n",
    "        decom_8b_k.append(tuple(sr_8b_k))\n",
    "        decom_8b_dQ.append(tuple(sr_8b_dQ))\n",
    "        level -= 1\n",
    "    print()\n",
    "    BPP = (write(decom_8b_k, f\"/tmp/{Q_step}_\", 0)[0]*8)/(YUV_img.shape[0]*YUV_img.shape[1])\n",
    "    decom_dQ = to_16bits(decom_8b_dQ)\n",
    "    return BPP, decom_dQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_RD_curve_8b(img, YUV, wavelet, N_levels, Q_factors, Q_steps, write):\n",
    "    print(\"Q_steps =\", Q_steps)\n",
    "    print(\"Q_factors =\", Q_factors)\n",
    "    YUV_img = YUV.from_RGB(img)\n",
    "    avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "    print(f\"avgs={avgs}\")\n",
    "    for c in range(3):\n",
    "        YUV_img[..., c] -= int(avgs[c])\n",
    "    decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "    RD_curve = []\n",
    "    for Q_step in Q_steps:\n",
    "        BPP, decom_dQ = get_RD_point_8b(img, decom, Q_step, Q_factors, wavelet, N_levels, write)\n",
    "        YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "        for c in range(3):\n",
    "            YUV_img_dQ[..., c] += int(avgs[c])\n",
    "        img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "        img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "        RMSE = distortion.RMSE(img, img_dQ)\n",
    "        print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "        #RGB_image.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")\n",
    "        RD_curve.append((BPP, RMSE))\n",
    "    return RD_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = compute_normalized_gains(img.shape, wavelet, N_levels)\n",
    "print(gains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q_steps = [256, 128, 64, 32, 16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_factors = [1]*(N_levels*3+1)\n",
    "img = RGB_image.read(test_image).astype(np.int16)\n",
    "DWT_constantQ_unglued_8b = compute_RD_curve_8b(img, YUV, wavelet, N_levels, Q_factors, Q_steps, DWT.write_unglued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_factors = [math.sqrt(gains[0]/i) for i in gains]\n",
    "img = RGB_image.read(test_image).astype(np.int16)\n",
    "DWT_factorsQ_unglued_8b = compute_RD_curve_8b(img, YUV, wavelet, N_levels, Q_factors, Q_steps, DWT.write_unglued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_constantQ_unglued_8b), label=f\"Constant Q_step\")\n",
    "pylab.plot(*zip(*DWT_factorsQ_unglued_8b), label=f\"Using factors\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, unglued a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 bits/coefficient VS 16 bits/coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_constantQ_unglued), label=f\"DWT uniform Q (16 bits)\")\n",
    "pylab.plot(*zip(*DWT_constantQ_unglued_8b), label=f\"DWT uniform Q (8 bits)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better the 8 bits/coefficient version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_factorsQ_unglued), label=f\"Using factors (16 bits)\")\n",
    "pylab.plot(*zip(*DWT_factorsQ_unglued_8b), label=f\"Using factors (8 bits)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_RD_points = []\n",
    "with open(\"../YCoCg_2D_DCT_SQ/YCoCg_2D_DCT_SQ.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        DCT_RD_points.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DCT_RD_points), label=r\"Deadzone(2D-DCT($\\mathbf{\\Delta}^{\\mathrm{Y}}_i = \\mathbf{\\Delta}^{\\mathrm{Co}}_i = \\mathbf{\\Delta}^{\\mathrm{Cg}}_i)$)+PNG\")\n",
    "pylab.plot(*zip(*DWT_8b_constantQ), label=f\"DWT uniform Q (8 bits)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JPEG_RD_points = []\n",
    "with open(HOME + \"/repos/JPEG/JPEG.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        JPEG_RD_points.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JPEG2K_RD_points = []\n",
    "with open(HOME + \"/repos/JPEG2000/JPEG2000.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        JPEG2K_RD_points.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2D_VQ_RD_points = []\n",
    "with open(\"../spatial_color_VQ/VQ_2D_RGB_RD_points.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        _2D_VQ_RD_points.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DCT_RD_points), label=r\"Deadzone(2D-DCT($\\mathbf{\\Delta}^{\\mathrm{Y}}_i = \\mathbf{\\Delta}^{\\mathrm{Co}}_i = \\mathbf{\\Delta}^{\\mathrm{Cg}}_i)$)+PNG\")\n",
    "pylab.plot(*zip(*JPEG_RD_points), label=r\"JPEG\")\n",
    "pylab.plot(*zip(*JPEG2K_RD_points), label=r\"JPEG 2000\")\n",
    "pylab.plot(*zip(*DWT_factorsQ_unglued), label=f\"Deadzone(DWT({YUV.name}))+PNG ({wavelet_name})\")\n",
    "pylab.plot(*zip(*_2D_VQ_RD_points), label=\"VQ\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving R\n",
    "\n",
    "JPEG2000 and our codec are quite similar, except in the entropy codec (JPEG2000 uses a bit-plane encoder based on a [MQ-codec](https://ieeexplore.ieee.org/document/4540263), and we are using PNG).\n",
    "\n",
    "If we visualize the subbands, it's obvious that there is a dependency between the three subbands of the same spatial resolution level $l$, and also a dependency between such subbands and the subband that represents the spatial resolution level $l+1$ (considering that if $l=0$ we have the original resolution).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RGB_image.show(img)\n",
    "decom = DWT.analyze(img, wavelet, 3)\n",
    "sb_index = 0\n",
    "RGB_image.show((normalize(decom[0])), '')\n",
    "print(sb_index, decom[0].max(), decom[0].min())\n",
    "for sr in decom[1:]:\n",
    "    view_sr = []\n",
    "    for sb in sr:\n",
    "        sb_index += 1\n",
    "        view_sb = (normalize(sb) * 255).astype(np.uint8)\n",
    "        view_sr.append(view_sb)\n",
    "        RGB_image.show(view_sb, '')\n",
    "        print(sb_index, sb.max(), sb.min())\n",
    "    view_decom.append(tuple(view_sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other interesting aspects that worth noting are:\n",
    "1. Orthogonal transforms are not linear in phase, which implies that the coefficients that result from the same structure are placed in different coordinates in the transform domain, with respect to the coordinates of the coefficients in the previous resolution level. However, orthogonal transform are more efficient than biorthogonal transforms concentrating energy.\n",
    "2. Inside of a filtering orientation (horizontal, vertical, o diagonal), the pattern shown by a 2D block in a subband of the level $l$ tends to be found in the level $l-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A proposal\n",
    "\n",
    "The idea of the following encoder is exploit the local spatial correlation with VQ and the global one with PNG, and to exploit the multiresolution correlation reusing the code-books, as much as possible, inside of each spatial orientation. In the following algorithm, all the code-books have a number of code-vectors of size 2x2 (the code-book length controls R and obviously, D, and therefore, no scalar quantization is required). Notice that this algorithm should perform well with any dyadic DWT transform, regardless of its phase linearity.\n",
    "\n",
    "1. Apply the pre-quantization pattern described previously to homogenize the dynamic range between spatial resolution levels.\n",
    "2. VQ the subband LL$^L$ ($L$ is the number of levels of the DWT). Compress the code-book with GZIP and send it. Compress the indexes with PNG.\n",
    "3. For each of the filtering orientations (LH, HL, and HH):\n",
    "    1. VQ the subband (of the level $L$). GZIP the code-book and send it. Compress the indexes with PNG.\n",
    "    2. For each of the rest of levels, starting with the highest one ($l=L-1$):\n",
    "        1. VQ the subband (in the level $l$).\n",
    "        2. Substract to the current code-book the used in the spatial resolution level $l+1$. GZIP the code-book and send it. Compress the indexes with PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YCoCg_2D_DWT_SQ.txt', 'w') as f:\n",
    "    for item in DWT_factorsQ_unglued_8b:\n",
    "        f.write(f\"{item[0]}\\t{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while True:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the Q_steps of the subbands depending on their RD contribution\n",
    "\n",
    "1. Select a Q_step for subband LL and compute the RD slope = reduction of the distortion (compared to the \"gray\" image) / number of bits required.\n",
    "2. Select the same Q_step for the next subband and compute the RD slope = reduction of the distortion (compared to the previous reconstructed image) / number of bits required. If the slope i higher, decrease the Q_step. If the slope is lower, increase the Q_step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Q_steps = range(256, 32, -4)\n",
    "\n",
    "img = RGB_image.read(test_image)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "optimized_Q_step = []\n",
    "for Q_step in Q_steps:\n",
    "    decom_8b = to_8bits(decom)\n",
    "    LL_8b = decom_8b[0]\n",
    "    _Q_step = compute_Q_step(Q_step, N_levels)\n",
    "    Q = Quantizer(Q_step=_Q_step)\n",
    "    LL_8b_k = Q.quantize(LL_8b) # Baybe bettter Q.get_indexes()\n",
    "    decom_8b_k = [(LL_8b_k + 128).astype(np.uint8)]\n",
    "    LL_8b_dQ = Q.dequantize(LL_8b_k) # Q.get_signal()\n",
    "    decom_8b_dQ = [LL_8b_dQ]\n",
    "    sbc_counter = 0\n",
    "    level = N_levels - 1\n",
    "    for sr_8b in decom_8b[1:]: # sr = spatial_resolution\n",
    "        sr_8b_k = []\n",
    "        sr_8b_dQ = []\n",
    "        for sb_8b in sr_8b: # sb = subband\n",
    "            _Q_step = compute_Q_step(Q_step, level)\n",
    "            Q = Quantizer(Q_step=_Q_step)\n",
    "            #Q = Quantizer(Q_step=100000)\n",
    "            sb_8b_k = Q.quantize(sb_8b)\n",
    "            sb_8b_dQ = Q.dequantize(sb_8b_k)\n",
    "            sr_8b_k.append((sb_8b_k + 128).astype(np.uint8))\n",
    "            print((sb_8b_k + 128).min(), (sb_8b_k + 128).max())\n",
    "            sr_8b_dQ.append(sb_8b_dQ)\n",
    "            sbc_counter += 1\n",
    "        decom_8b_k.append(tuple(sr_8b_k))\n",
    "        decom_8b_dQ.append(tuple(sr_8b_dQ))\n",
    "        level -= 1\n",
    "    BPP = (DWT.write_unglued(decom_8b_k, f\"/tmp/constant_{Q_step}_\", 0)[0]*8)/(YUV_img.shape[0]*YUV_img.shape[1])\n",
    "    decom_dQ = to_16bits(decom_8b_dQ)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "    img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "    optimized_Q_step.append((BPP, RMSE))\n",
    "    #RGB_image.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*optimized_Q_step), label=f\"optimized Q_step\")\n",
    "pylab.plot(*zip(*DWT_8b_constantQ_unglued), label=f\"DWT uniform Q (8 bits)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc='upper right')\n",
    "#plt.xlim([0, 1])\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = RGB_image.read(test_image).astype(np.int16)\n",
    "YUV_img = YUV.from_RGB(img)\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "\n",
    "gray_img = np.ones_like(img)*128\n",
    "YUV_gray_img = YUV.from_RGB(gray_img)\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "gray_decom = DWT.analyze(YUV_gray_img, wavelet, N_levels)\n",
    "\n",
    "optimized_Q_step = []\n",
    "for Q_step in Q_steps: # \"Master\" Q_step used for the LL subband.\n",
    "    # Slope LL subband\n",
    "    Q = Quantizer(Q_step=Q_step)\n",
    "    LL = decom[0]\n",
    "    LL_k = Q.quantize(LL) # Baybe bettter Q.get_indexes()\n",
    "    LL_dQ = Q.dequantize(LL_k) # Q.get_signal()\n",
    "    decom_k = [add_offset(LL_k)]\n",
    "    decom_dQ = [LL_dQ]\n",
    "    sbc_counter = 0\n",
    "    levels_counter = N_levels - 1\n",
    "    Q = Quantizer(Q_step=10000) # Rest high-freq subbands to zero\n",
    "    for sr in decom[1:]: # sr = spatial_resolution\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr: # sb = subband\n",
    "            sb_k = Q.quantize(sb)\n",
    "            sb_dQ = Q.dequantize(sb_k)\n",
    "            sr_k.append(add_offset(sb_k))\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            sbc_counter += 1\n",
    "        decom_k.append(tuple(sr_k))\n",
    "        decom_dQ.append(tuple(sr_dQ))\n",
    "        levels_counter += 1\n",
    "    N_bytes = RGB_image.write(add_offset(LL_k), f\"/tmp/1_\", 0)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "    img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "    optimized_Q_step.append((BPP, RMSE))\n",
    "    #RGB_image.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrame\n",
    "img = RGB_image.read(test_image)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "DWT_8b_constantQ_unglued2 = []\n",
    "for Q_step in Q_steps:\n",
    "    decom_8b = to_8bits(decom)\n",
    "    LL_8b = decom_8b[0]\n",
    "    _Q_step = compute_Q_step(Q_step, N_levels)\n",
    "    Q = Quantizer(Q_step=_Q_step)\n",
    "    LL_8b_k = Q.quantize(LL_8b) # Baybe bettter Q.get_indexes()\n",
    "    decom_8b_k = [(LL_8b_k + 128).astype(np.uint8)]\n",
    "    LL_8b_dQ = Q.dequantize(LL_8b_k) # Q.get_signal()\n",
    "    decom_8b_dQ = [LL_8b_dQ]\n",
    "    sbc_counter = 0\n",
    "    level = N_levels - 1\n",
    "    energy_BPP_cost = []\n",
    "    for sr_8b in decom_8b[1:]: # sr = spatial_resolution\n",
    "        sr_8b_k = []\n",
    "        sr_8b_dQ = []\n",
    "        print(\"sbc_counter =\", sbc_counter, \"energy =\", sbc_energy)\n",
    "        BPP_cost = RGB_image.write((sb_8b_k + 128).astype(np.uint8), f\"/tmp/1_\", 0)\n",
    "        print(\"BPP_cost =\", BPP_cost)\n",
    "        energy_BPP_cost.append(sbc_energy/BPP_cost)\n",
    "        print(\"energy/BPP_cost =\", energy__BPP_cost[-1])\n",
    "        for sb_8b in sr_8b: # sb = subband\n",
    "            _Q_step = compute_Q_step(Q_step, level)\n",
    "            Q = Quantizer(Q_step=_Q_step)\n",
    "            sb_8b_k = Q.quantize(sb_8b)\n",
    "            sb_8b_dQ = Q.dequantize(sb_8b_k)\n",
    "            sr_8b_k.append((sb_8b_k + 128).astype(np.uint8))\n",
    "            sr_8b_dQ.append(sb_8b_dQ)\n",
    "            sbc_counter += 1\n",
    "            sbc_energy = information.energy(sb_8b_dQ)\n",
    "            print(\"sbc_counter =\", sbc_counter, \"energy =\", sbc_energy)\n",
    "            BPP_cost = RGB_image.write((sb_8b_k + 128).astype(np.uint8), f\"/tmp/1_\", 0)\n",
    "            print(\"BPP_cost =\", BPP_cost)\n",
    "            energy_BPP_cost.append(sbc_energy/BPP_cost)\n",
    "            print(\"energy/BPP_cost =\", energy__BPP_cost[-1])\n",
    "        decom_8b_k.append(tuple(sr_8b_k))\n",
    "        decom_8b_dQ.append(tuple(sr_8b_dQ))\n",
    "        level -= 1\n",
    "    \n",
    "    BPP = (DWT.write_unglued(decom_8b_k, f\"/tmp/constant_{Q_step}_\", 0)[0]*8)/(YUV_img.shape[0]*YUV_img.shape[1])\n",
    "    decom_dQ = to_16bits(decom_8b_dQ)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "    img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "    DWT_8b_constantQ_unglued2.append((BPP, RMSE))\n",
    "    #RGB_image.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gains = []\n",
    "x = np.zeros(shape=(512, 512, 3))\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "coeff_value = y[0].size\n",
    "y[0][...] = coeff_value/y[0].size\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "gains.append(information.average_energy(z))\n",
    "prev_sb = y[0]\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        prev_sb[...] = 0.0\n",
    "        sb[...] = coeff_value/sb.size\n",
    "        z = DWT.synthesize(y, wavelet, N_levels)\n",
    "        gains.append(information.average_energy(z))\n",
    "        prev_sb = sb\n",
    "        \n",
    "x = np.empty(shape=(512, 512, 3))\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "coeff_value = y[0].size\n",
    "y[0][...] = coeff_value/y[0].size\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        sb[...] = coeff_value/sb.size\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "z_energy = information.average_energy(z)\n",
    "\n",
    "gains = [gain/z_energy for gain in gains]\n",
    "print(\"Unitary (normalized) inverse transform subband gains:\", gains)\n",
    "print(np.testing.assert_almost_equal(sum(gains), 1.0))\n",
    "print(sum(gains))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the distortion in the transform domain (TO-DO)\n",
    "\n",
    "Only works if the colorand the spatial transforms are orthogonal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_steps = [256, 128, 64, 32, 16, 8, 4, 2, 1]\n",
    "img = RGB_image.read(test_image)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "LL = decom[0]\n",
    "for Q_step in Q_steps:\n",
    "    Q = Quantizer(Q_step=Q_step)\n",
    "    LL_k = Q.quantize(LL)\n",
    "    LL_dQ = Q.dequantize(LL_k)\n",
    "    # ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform quantization using bi-orthogonal filters (TO-DO)\n",
    "\n",
    "This procedure should be used when the YUV/DWT transform is not orthonormal (for example, when using the YCoCg color space and/or biorthogonal DWT filters). In this case we must consider the subband gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wavelet)\n",
    "#wavelet = 'bior3.5'\n",
    "wavelet = 'db5'\n",
    "img = image_3.read(test_image).astype(np.int16)\n",
    "DWT.compute_gains(wavelet=wavelet, N_levels=N_levels, pixels_in_y=img.shape[0], pixels_in_x=img.shape[1])\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally ... can we increase the RD performance using RDO?\n",
    "\n",
    "Let's do that, for a given RD point, the subband-components contribute (in general, approximately) the same to que quality of the reconstruction.\n",
    "\n",
    "Algorithm:\n",
    "1. Read the image.\n",
    "2. Transform it to the YCoCg domain.\n",
    "3. Transform each component to the DWT domain.\n",
    "4. Estimate the RD curve for each subband-component.\n",
    "5. Compute the slope of each step of each curve and put all the tuples (slopes, quantization steps, subband number) in the same list.\n",
    "6. Sort the previous list by the slope field.\n",
    "7. Compute the RD curve that progressively uses descending slopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image and move it to the 0-mean YCoCg domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_3.read(test_image, 0)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the 2D-DWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of RD points for each RD curve (subband-component) and the corresponding lists of RD slopes between these points\n",
    "There is a RD curve per subband-component. The first coordinate of each point is the rate and the second coordinate is the corresponding distortion.\n",
    "For rate=0, the RMSE is the energy of the subband-component.\n",
    "Notice that:\n",
    "1. We have considered that the YUV/DWT transform is orthogonal and therefore, the distortion of the recontructed image can be estimated in the transform domain.\n",
    "2. The slope cannot be computed for the first point of each RD curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_points = []\n",
    "RD_slopes = []\n",
    "for _c in range(N_components):\n",
    "    sbc = decom[0][..., _c]\n",
    "    RD_points.append([(0, information.average_energy(sbc))]) # Work with RMSE's that are average distortions\n",
    "    RD_slopes.append([])\n",
    "level = N_levels - 1\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            sbc = sb[..., _c]\n",
    "            sbc_avg_energy = information.average_energy(sbc)\n",
    "            # The first point of each RD curve has a maximum distortion equal\n",
    "            # to the energy of the subband and a rate = 0\n",
    "            RD_points.append([(0, sbc_avg_energy)])\n",
    "            RD_slopes.append([])\n",
    "    level -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"subband-component, RD-point\")\n",
    "for _i,_j in enumerate(RD_points):\n",
    "    print(_i,_j)\n",
    "    if not ((_i+1) % 3):\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### Populate the rest of points of each curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subband LL\n",
    "sbc_number = 0\n",
    "for _c in range(N_components):\n",
    "    sbc = decom[0][..., _c]\n",
    "    Q_step_number = 0\n",
    "    for Q_step in Q_steps:\n",
    "        sbc_k = Q.quantize(sbc, Q_step)\n",
    "        sbc_dQ = Q.dequantize(sbc_k, Q_step)\n",
    "        RMSE = distortion.RMSE(sbc, sbc_dQ)\n",
    "        #print(sbc.max(), sbc.min(), sbc_dQ.max(), sbc_dQ.min())\n",
    "        #BPP = image_1.write((sbc_k + 128).astype(np.uint8), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "        BPP = image_1.write((sbc_k + 32768).astype(np.uint16), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "        #BPP = information.entropy(sbc_k.astype(np.int16).flatten())\n",
    "        point = (BPP, RMSE)\n",
    "        RD_points[sbc_number].append(point)\n",
    "        delta_BPP = BPP - RD_points[_c][Q_step_number][0]\n",
    "        delta_RMSE = RD_points[_c][Q_step_number][1] - RMSE\n",
    "        if delta_BPP > 0:\n",
    "            slope = delta_RMSE/delta_BPP\n",
    "        else:\n",
    "            slope = 0\n",
    "        print(f\"sbc_number={sbc_number} Q_step={Q_step} BPP={point[0]} RMSE={point[1]} slope={slope}\")\n",
    "        if slope > 0:\n",
    "            RD_slopes[_c].append((Q_step, slope, _c))\n",
    "        Q_step_number += 1\n",
    "    sbc_number += 1\n",
    "\n",
    "# Rest of subbands\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            sbc = sb[..., _c]\n",
    "            Q_step_number = 0\n",
    "            for Q_step in Q_steps:\n",
    "                sbc_k = Q.quantize(sbc, Q_step)\n",
    "                sbc_dQ = Q.dequantize(sbc_k, Q_step)\n",
    "                RMSE = distortion.RMSE(sbc, sbc_dQ)\n",
    "                #BPP = image_1.write((sbc_k + 128).astype(np.uint8), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "                BPP = image_1.write((sbc_k + 32768).astype(np.uint16), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "                #sbc_BPP = information.entropy(sbc_k.astype(np.int16).flatten())\n",
    "                point = (BPP, RMSE)\n",
    "                RD_points[sbc_number].append(point)\n",
    "                delta_BPP = BPP - RD_points[sbc_number][Q_step_number][0]\n",
    "                delta_RMSE = RD_points[sbc_number][Q_step_number][1] - RMSE\n",
    "                if delta_BPP > 0:\n",
    "                    slope = delta_RMSE/delta_BPP\n",
    "                else:\n",
    "                    slope = 0\n",
    "                print(f\"sbc_number={sbc_number} Q_step={Q_step} BPP={point[0]} RMSE={point[1]} slope={slope}\")\n",
    "                if slope > 0:\n",
    "                    RD_slopes[sbc_number].append((Q_step, slope, sbc_number))\n",
    "                Q_step_number += 1\n",
    "            sbc_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(BPP, RMSE)\")\n",
    "for _i, _j in enumerate(RD_points):\n",
    "    print(_i, _j)\n",
    "    if not ((_i+1) % 3):\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"subband-component, (Q_step, slope, subband-component number)\")\n",
    "for _i, _j in enumerate(RD_slopes):\n",
    "    print(_i, _j)\n",
    "    if not ((_i+1) % 3):\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove points that do not belong to the convex-hull\n",
    "Remove those points of each subband-component that do not satisfy that the slope is higher than the next point of the curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_slopes(slopes):\n",
    "    filtered_slopes = []\n",
    "    slopes_iterator = iter(slopes)\n",
    "    prev = next(slopes_iterator)\n",
    "    for curr in slopes_iterator:\n",
    "        if prev[1] < curr[1]:\n",
    "            print(f\"deleted {prev}\")\n",
    "        else:\n",
    "            filtered_slopes.append(prev)\n",
    "        prev = curr\n",
    "    filtered_slopes.append(prev)\n",
    "    return filtered_slopes\n",
    "\n",
    "filtered_slopes = []\n",
    "for i in RD_slopes:\n",
    "    filtered_slopes.append(filter_slopes(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Q_step, slope, subband-component number\")\n",
    "for _i, _j in enumerate(filtered_slopes):\n",
    "    print(_i, \"---\", _j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all the lists together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = []\n",
    "for l in filtered_slopes:\n",
    "    for i in l:\n",
    "        single_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"(quantization step, slope, subband-component number)\")\n",
    "single_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the list of quantization steps, slopes, and subband-components\n",
    "By slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progression_of_deltas = sorted(single_list, key=lambda _x: _x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"(quantization step, slope, subband-component number)\")\n",
    "progression_of_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of subband-components =\", (N_levels*3+1)*N_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the progression of quantization steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_steps_pattern = 3*[''] # There are 3 color components\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            Q_steps_pattern.append('')\n",
    "            \n",
    "for i, j in enumerate(progression_of_deltas):\n",
    "    Q_steps_pattern[j[2]] = j[0]\n",
    "    print(i, j, Q_steps_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(d, s):\n",
    "    c = 0\n",
    "    for i in d[0]:\n",
    "        print(s, i, end=' ')\n",
    "        c += 1\n",
    "        if c > 3:\n",
    "            break\n",
    "    for sr in d[1:]:\n",
    "        for sb in sr:\n",
    "            c = 0\n",
    "            for i in sb:\n",
    "                print(s, i, end=' ')\n",
    "                c += 1\n",
    "                if c > 3:\n",
    "                    break\n",
    "    print()\n",
    "\n",
    "def _quantize(decom, Q_steps):\n",
    "    decom_k = []\n",
    "    decom_k.append(Q.quantize_components(decom[0], Q_steps[0:3]))\n",
    "    for sr in decom[1:]:\n",
    "        decom_k.append(Q.sr)\n",
    "    print()\n",
    "    return decom_k\n",
    "\n",
    "def _dequantize(decom_k, Q_steps):\n",
    "    decom_dQ = []\n",
    "    decom_dQ.append(decom_k[0])\n",
    "    for sr_k in decom_k[1:]:\n",
    "        decom_dQ.append(sr_k)\n",
    "    print()\n",
    "    return decom_dQ\n",
    "    \n",
    "def quantize_components_uint16(x, Q_steps):\n",
    "    '''Quantize each component of <x> using a quantization step per component.'''\n",
    "    x_k = np.empty_like(x, dtype=np.int32)\n",
    "    for c in range(x.shape[2]):\n",
    "        x_k[..., c] = Q.quantize(x[..., c], Q_steps[c]) + 32768\n",
    "    return x_k.astype(np.uint16)\n",
    "\n",
    "def dequantize_components_uint16(x_k, Q_steps):\n",
    "    '''Dequantize each component of <x_k> using an independent quantization step.'''\n",
    "    x_dQ = np.empty_like(x_k, dtype=np.int32)\n",
    "    for c in range(x_k.shape[2]):\n",
    "        x_dQ[..., c] = Q.dequantize(x_k[..., c].astype(np.int32) - 32768, Q_steps[c])\n",
    "    return x_dQ\n",
    "\n",
    "def quantize(decom, Q_steps):\n",
    "    '''Quantize and add 32768.'''\n",
    "    decom_k = []\n",
    "    #decom_k.append(decom[0])\n",
    "    decom_k.append(quantize_components_uint16(decom[0], Q_steps[0:3]))\n",
    "    #print(decom[0].max(), decom[0].min(), decom_k[0].max(), decom_k[0].min())\n",
    "    sbc_number = 3\n",
    "    for sr in decom[1:]:\n",
    "        sr_k = []\n",
    "        for sb in sr:\n",
    "            sb_k = quantize_components_uint16(sb, Q_steps[sbc_number:sbc_number + 3])\n",
    "            sr_k.append(sb_k)\n",
    "            sbc_number += 3\n",
    "        #decom_k.append(sr)\n",
    "        decom_k.append(tuple(sr_k))\n",
    "    return decom_k\n",
    "\n",
    "def dequantize(decom_k, Q_steps):\n",
    "    decom_dQ = []\n",
    "    #decom_dQ.append(decom_k[0])\n",
    "    decom_dQ.append(dequantize_components_uint16(decom_k[0], Q_steps[0:3]))\n",
    "    sbc_number = 3\n",
    "    for sr_k in decom_k[1:]:\n",
    "        sr_dQ = []\n",
    "        for sb_k in sr_k:\n",
    "            sb_dQ = dequantize_components_uint16(sb_k, Q_steps[sbc_number:sbc_number + 3])\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            sbc_number += 3\n",
    "        #decom_dQ.append(sr_k)\n",
    "        decom_dQ.append(tuple(sr_dQ))\n",
    "    return decom_dQ\n",
    "    \n",
    "def quantize_sr(sr, Q_step):\n",
    "    '''Quantize a spatial resolution of the DWT (3 multicomponent subbands) using\n",
    "    3*N_components independent quantization steps'''\n",
    "    return tuple([Q.quantize(i, Q_step) for i in sr])\n",
    "\n",
    "def _quantize(decomposition, Q_steps):\n",
    "    LL = decomposition[0]\n",
    "    LL_k = np.empty_like(LL, dtype=np.int16)\n",
    "    for _c in range(N_components):\n",
    "        LLc = LL[..., _c]\n",
    "        LL_k[..., _c] = LLc # Q.quantize(LLc, Q_steps[_c])\n",
    "    decomposition_k = [LL_k]\n",
    "    sbc_number = 3\n",
    "    for sr in decomposition[1:]:\n",
    "        #print(\"sr\", len(sr))\n",
    "        sr_k = []\n",
    "        for sb in sr:\n",
    "            sbc_k = np.empty_like(sb)\n",
    "            for _c in range(N_components):\n",
    "                sbc = sb[..., _c]\n",
    "                #print(len(Q_steps), sbc_number)\n",
    "                sbc_k[..., _c] = sbc # Q.quantize(sbc, Q_steps[sbc_number])\n",
    "                #sbc_k = Q.quantize(sbc, Q_steps[sbc_number])\n",
    "                sbc_number += 1\n",
    "            sr_k.append(sbc_k)\n",
    "        decomposition_k.append(tuple(sr_k))\n",
    "    return decomposition\n",
    "    #return decomposition_k\n",
    "\n",
    "def _dequantize(decomposition_k, Q_steps):\n",
    "    LL_k = decomposition_k[0]\n",
    "    LL_dQ = np.empty_like(LL_k).astype(np.float64)\n",
    "    for _c in range(N_components):\n",
    "        LLc_k = LL_k[..., _c]\n",
    "        LL_dQ[..., _c] = LLc_k# Q.dequantize(LLc_k, Q_steps[_c])\n",
    "    decomposition_dQ = [LL_dQ]\n",
    "    sbc_number = 3\n",
    "    for sr_k in decomposition_k[1:]:\n",
    "        sr_dQ = []\n",
    "        #print(\"sr_k\", len(sr_k))\n",
    "        for sb_k in sr_k:\n",
    "            sbc_dQ = np.empty_like(sb_k).astype(np.float64)\n",
    "            for _c in range(N_components):\n",
    "                sbc_k = sb_k[..., _c]\n",
    "                #print(len(Q_steps), sbc_number)\n",
    "                sbc_dQ[..., _c] = sbc_k #Q.dequantize(sbc_k, Q_steps[sbc_number])\n",
    "                sr_dQ.append(sbc_dQ)\n",
    "                sbc_number += 1\n",
    "        decomposition_dQ.append(tuple(sr_dQ))\n",
    "    return decomposition_k\n",
    "    #return decomposition_dQ\n",
    "\n",
    "def resolution_level(sb_number):\n",
    "    '''Resolution level in decomposition.'''\n",
    "    if sb_number > 0:\n",
    "        return ((sb_number - 1) // 3) + 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def subband_index(sb_number):\n",
    "    '''Subband index in resolution level.'''\n",
    "    if sb_number > 0:\n",
    "        return (sb_number % 3) - 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Find the optimal RD curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DWT_RDO_16_glued = []\n",
    "\n",
    "# Initially all the quantization steps structure are \"infinite\"=10^4.\n",
    "Q_steps_pattern = 3*[10**4] # There are 3 color components\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            Q_steps_pattern.append(10**4)\n",
    "\n",
    "slope_index = 0\n",
    "for s in progression_of_deltas:\n",
    "    sbc_number = s[2]\n",
    "    Q_steps_pattern[sbc_number] = s[0]\n",
    "    decom_k = quantize(decom, Q_steps_pattern)\n",
    "    BPP = (DWT.write_glued(decom_k, f\"/tmp/optimal_{slope_index}_\", 0)[0]*8)/YUV_img.size\n",
    "    decom_dQ = dequantize(decom_k, Q_steps_pattern)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = np.clip(YUV.to_RGB(YUV_img_dQ), a_min=0, a_max=255)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_steps_pattern={Q_steps_pattern} BPP={BPP} RMSE={RMSE}\")\n",
    "    #if not slope_index % 10:\n",
    "    #    image_3.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")\n",
    "    DWT_RDO_16_glued.append((BPP, RMSE))\n",
    "    slope_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DWT_RDO_16_glued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT_RDO = []\n",
    "with open(HOME + \"/Sistemas-Multimedia.github.io/milestones/07-DCT/DCT_RDO.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        rate, _distortion = line.split('\\t')\n",
    "        DCT_RDO.append((float(rate), float(_distortion)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_8b_constantQ), label=f\"{YUV.name}/{N_levels}-{wavelet_name} (glued, 8 bits, without RDO)\")\n",
    "pylab.plot(*zip(*DWT_RDO_16_glued), label=f\"{YUV.name}/{N_levels}-{wavelet_name} (glued, 16 bits, with RDO)\")\n",
    "pylab.plot(*zip(*DCT_RDO), label=\"YCoCg/8x8-DCT (with RDO)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc=\"best\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using unglued PNG images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image and move it to the 0-mean YCoCg domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_3.read(test_image, 0)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute (the 8-bit) 2D-DWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of RD points for each RD curve (subband-component) and the corresponding lists of RD slopes between these points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_points = []\n",
    "RD_slopes = []\n",
    "for _c in range(N_components):\n",
    "    sbc = decom[0][..., _c]#.astype(np.int32) << N_levels #* math.pow(2, N_levels)\n",
    "    RD_points.append([(0, information.average_energy(sbc))]) # Work with RMSE's that are average distortions\n",
    "    RD_slopes.append([])\n",
    "level = N_levels - 1\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            sbc = sb[..., _c]#.astype(np.int32) << level #* math.pow(2, level)\n",
    "            sbc_avg_energy = information.average_energy(sbc)\n",
    "            # The first point of each RD curve has a maximum distortion equal\n",
    "            # to the energy of the subband and a rate = 0\n",
    "            RD_points.append([(0, sbc_avg_energy)])\n",
    "            RD_slopes.append([])\n",
    "    level -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"subband-component, RD-point\")\n",
    "for _i,_j in enumerate(RD_points):\n",
    "    print(_i,_j)\n",
    "    if not ((_i+1) % 3):\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### Populate the rest of points of each curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subband LL\n",
    "sbc_number = 0\n",
    "for _c in range(N_components):\n",
    "    sbc = decom[0][..., _c]#.astype(np.int32) << N_levels #* math.pow(2, N_levels)\n",
    "    Q_step_number = 0\n",
    "    for Q_step in Q_steps:\n",
    "        #_Q_step = compute_Q_step(Q_step, N_levels)\n",
    "        sbc_k = Q.quantize(sbc, Q_step)\n",
    "        sbc_dQ = Q.dequantize(sbc_k, Q_step)\n",
    "        RMSE = distortion.RMSE(sbc, sbc_dQ)\n",
    "        #print(sbc.max(), sbc.min(), sbc_dQ.max(), sbc_dQ.min())\n",
    "        #BPP = image_1.write((sbc_k + 128).astype(np.uint8), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "        BPP = image_1.write((sbc_k + 32768).astype(np.uint16), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "        #BPP = information.entropy(sbc_k.astype(np.int16).flatten())\n",
    "        point = (BPP, RMSE)\n",
    "        RD_points[sbc_number].append(point)\n",
    "        delta_BPP = BPP - RD_points[_c][Q_step_number][0]\n",
    "        delta_RMSE = RD_points[_c][Q_step_number][1] - RMSE\n",
    "        if delta_BPP > 0:\n",
    "            slope = delta_RMSE/delta_BPP\n",
    "        else:\n",
    "            slope = 0#100**10\n",
    "        print(f\"sbc_number={sbc_number} Q_step={Q_step} BPP={point[0]} RMSE={point[1]} slope={slope}\")\n",
    "        #RD_slopes[_c].append((Q_step, slope, _c))\n",
    "        #RD_slopes[_c].append((_Q_step, slope, _c))\n",
    "        if slope > 0:\n",
    "            RD_slopes[_c].append((Q_step, slope, _c))\n",
    "        Q_step_number += 1\n",
    "    sbc_number += 1\n",
    "\n",
    "# Rest of subbands\n",
    "level = N_levels - 1\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            sbc = sb[..., _c]#.astype(np.int32) << level #* math.pow(2, level)\n",
    "            Q_step_number = 0\n",
    "            for Q_step in Q_steps:\n",
    "                #_Q_step = compute_Q_step(Q_step, level)\n",
    "                sbc_k = Q.quantize(sbc, Q_step)\n",
    "                sbc_dQ = Q.dequantize(sbc_k, Q_step)\n",
    "                RMSE = distortion.RMSE(sbc, sbc_dQ)\n",
    "                #BPP = image_1.write((sbc_k + 128).astype(np.uint8), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "                BPP = image_1.write((sbc_k + 32768).astype(np.uint16), f\"/tmp/{sbc_number}_{Q_step}_\", 0)*8/sbc.size\n",
    "                #sbc_BPP = information.entropy(sbc_k.astype(np.int16).flatten())\n",
    "                point = (BPP, RMSE)\n",
    "                RD_points[sbc_number].append(point)\n",
    "                delta_BPP = BPP - RD_points[sbc_number][Q_step_number][0]\n",
    "                delta_RMSE = RD_points[sbc_number][Q_step_number][1] - RMSE\n",
    "                if delta_BPP > 0:\n",
    "                    slope = delta_RMSE/delta_BPP\n",
    "                else:\n",
    "                    slope = 0\n",
    "                print(f\"sbc_number={sbc_number} Q_step={Q_step} BPP={point[0]} RMSE={point[1]} slope={slope}\")\n",
    "                if slope > 0:\n",
    "                    RD_slopes[sbc_number].append((Q_step, slope, sbc_number))\n",
    "                Q_step_number += 1\n",
    "            sbc_number += 1\n",
    "    level -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(BPP, RMSE)\")\n",
    "for _i, _j in enumerate(RD_points):\n",
    "    print(_i, _j)\n",
    "    if not ((_i+1) % 3):\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"subband-component, (Q_step, slope, subband-component number)\")\n",
    "for _i, _j in enumerate(RD_slopes):\n",
    "    print(_i, _j)\n",
    "    if not ((_i+1) % 3):\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove points that do not belong to the convex-hull "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_slopes(slopes):\n",
    "    filtered_slopes = []\n",
    "    slopes_iterator = iter(slopes)\n",
    "    prev = next(slopes_iterator)\n",
    "    for curr in slopes_iterator:\n",
    "        if prev[1] < curr[1]:\n",
    "            print(f\"deleted {prev}\")\n",
    "        else:\n",
    "            filtered_slopes.append(prev)\n",
    "        prev = curr\n",
    "    filtered_slopes.append(prev)\n",
    "    return filtered_slopes\n",
    "\n",
    "filtered_slopes = []\n",
    "for i in RD_slopes:\n",
    "    filtered_slopes.append(filter_slopes(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all the lists together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = []\n",
    "for l in filtered_slopes:\n",
    "    for i in l:\n",
    "        single_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"(quantization step, slope, subband-component number)\")\n",
    "single_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the list of quantization steps, slopes, and subband-components\n",
    "By slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progression_of_deltas = sorted(single_list, key=lambda _x: _x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"(quantization step, slope, subband-component number)\")\n",
    "progression_of_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of subband-components =\", (N_levels*3+1)*N_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the progression of quantization steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_steps_pattern = 3*[''] # There are 3 color components\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            Q_steps_pattern.append('')\n",
    "            \n",
    "for i, j in enumerate(progression_of_deltas):\n",
    "    Q_steps_pattern[j[2]] = j[0]\n",
    "    print(i, j, Q_steps_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_components(x, Q_steps):\n",
    "    '''Quantize each component of <x> using a quantization step per component.'''\n",
    "    x_k = np.empty_like(x, dtype=np.int32)\n",
    "    for c in range(x.shape[2]):\n",
    "        x_k[..., c] = Q.quantize(x[..., c], Q_steps[c]) # + 128\n",
    "    return x_k\n",
    "\n",
    "def dequantize_components(x_k, Q_steps):\n",
    "    '''Dequantize each component of <x_k> using an independent quantization step.'''\n",
    "    x_dQ = np.empty_like(x_k, dtype=np.int32)\n",
    "    for c in range(x_k.shape[2]):\n",
    "        #x_dQ[..., c] = Q.dequantize(x_k[..., c].astype(np.uint32) - 128, Q_steps[c])\n",
    "        x_dQ[..., c] = Q.dequantize(x_k[..., c], Q_steps[c])\n",
    "    return x_dQ\n",
    "\n",
    "def quantize(decom, Q_steps):\n",
    "    decom_k = []\n",
    "    #decom_k.append(decom[0])\n",
    "    decom_k.append(quantize_components(decom[0], Q_steps[0:3]))\n",
    "    sbc_number = 3\n",
    "    for sr in decom[1:]:\n",
    "        sr_k = []\n",
    "        for sb in sr:\n",
    "            sb_k = quantize_components(sb, Q_steps[sbc_number:sbc_number + 3])\n",
    "            sr_k.append(sb_k)\n",
    "            sbc_number += 3\n",
    "        #decom_k.append(sr)\n",
    "        decom_k.append(tuple(sr_k))\n",
    "    return decom_k\n",
    "\n",
    "def dequantize(decom_k, Q_steps):\n",
    "    decom_dQ = []\n",
    "    #decom_dQ.append(decom_k[0])\n",
    "    decom_dQ.append(dequantize_components(decom_k[0], Q_steps[0:3]))\n",
    "    sbc_number = 3\n",
    "    for sr_k in decom_k[1:]:\n",
    "        sr_dQ = []\n",
    "        for sb_k in sr_k:\n",
    "            sb_dQ = dequantize_components(sb_k, Q_steps[sbc_number:sbc_number + 3])\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            sbc_number += 3\n",
    "        #decom_dQ.append(sr_k)\n",
    "        decom_dQ.append(tuple(sr_dQ))\n",
    "    return decom_dQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Find the optimal RD curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DWT_RDO_16_unglued = []\n",
    "\n",
    "# Initially all the quantization steps structure are \"infinite\"=10^4.\n",
    "Q_steps_pattern = 3*[10**4] # There are 3 color components\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            Q_steps_pattern.append(10**4)\n",
    "\n",
    "slope_index = 0\n",
    "for s in progression_of_deltas:\n",
    "    sbc_number = s[2]\n",
    "    Q_steps_pattern[sbc_number] = s[0]\n",
    "    decom_k = quantize(decom, Q_steps_pattern)\n",
    "    disk_decom_k = [add_offset(decom_k[0])]\n",
    "    for sr_k in decom_k[1:]:\n",
    "        disk_sr_k = []\n",
    "        for sb_k in sr_k:\n",
    "            disk_sr_k.append(add_offset(sb_k))\n",
    "        disk_decom_k.append(tuple(disk_sr_k))\n",
    "    BPP = (DWT.write_unglued(disk_decom_k, f\"/tmp/optimal_{slope_index}_\", 0)[0]*8)/img.size\n",
    "    #BPP = (write_compact_decomposition(decom_k, f\"/tmp/optimal_{slope_index}_\", 0)*8)/YUV_img.size\n",
    "    #BPP = entropy(y_k)\n",
    "    decom_dQ = dequantize(decom_k, Q_steps_pattern)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = np.clip(YUV.to_RGB(YUV_img_dQ), a_min=0, a_max=255)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_steps_pattern={Q_steps_pattern} BPP={BPP} RMSE={RMSE}\")\n",
    "    #if not slope_index % 10:\n",
    "    #    image_3.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")\n",
    "    DWT_RDO_16_unglued.append((BPP, RMSE))\n",
    "    slope_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DWT_RDO_16_unglued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_8b_constantQ), label=f\"{YUV.name}/{N_levels}-{wavelet_name} (glued, 8 bits, without RDO)\")\n",
    "pylab.plot(*zip(*DWT_RDO_16_glued), label=f\"{YUV.name}/{N_levels}-{wavelet_name} (glued, 16 bits, with RDO)\")\n",
    "pylab.plot(*zip(*DWT_RDO_16_unglued), label=f\"{YUV.name}/{N_levels}-{wavelet_name} (unglued, 16 bits, with RDO)\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc=\"best\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDO using bi-orthogonal filters (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPEG2000 RD curve (and comparison) (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the rest ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __read_image(prefix):\n",
    "    x = image_3.read(prefix, 0)\n",
    "    if len(x.shape) == 2:\n",
    "        extended_x = np.zeros(shape=(x.shape[0],  x.shape[1], 3), dtype=np.uint16) \n",
    "        extended_x[..., 0] = x\n",
    "        return extended_x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def _write_compact_decomposition(decom, prefix, image_number):\n",
    "    rows = decom[len(decom)-1][0].shape[0]*2\n",
    "    cols = decom[len(decom)-1][0].shape[1]*2\n",
    "    coms = decom[0].shape[2]\n",
    "    image_shape = (rows, cols, coms)\n",
    "    view = np.empty(image_shape, np.uint16)\n",
    "\n",
    "    # LL subband\n",
    "    view[0:decom[0].shape[0],\n",
    "         0:decom[0].shape[1]] = (decom[0].astype(np.int32) + 32768).astype(np.uint16)\n",
    "\n",
    "    for l in range(len(decom)-1):\n",
    "\n",
    "        # LH\n",
    "        view[0:decom[l+1][0].shape[0],\n",
    "             decom[l+1][0].shape[1]:decom[l+1][0].shape[1]*2] =\\\n",
    "                (decom[l+1][0].astype(np.int32) + 32768).astype(np.uint16)\n",
    "\n",
    "        # HL\n",
    "        view[decom[l+1][1].shape[0]:decom[l+1][1].shape[0]*2,\n",
    "             0:decom[l+1][1].shape[1]] =\\\n",
    "                (decom[l+1][1].astype(np.int32) + 32768).astype(np.uint16)\n",
    "\n",
    "        # HH\n",
    "        view[decom[l+1][2].shape[0]:decom[l+1][2].shape[0]*2,\n",
    "             decom[l+1][2].shape[1]:decom[l+1][2].shape[1]*2] =\\\n",
    "                (decom[l+1][2].astype(np.int32) + 32768).astype(np.uint16)\n",
    "            \n",
    "    return image.write(view, prefix, image_3_number)\n",
    "    \n",
    "def write_compact_decomposition(decom, prefix, image_number):\n",
    "    rows = decom[len(decom)-1][0].shape[0]*2\n",
    "    cols = decom[len(decom)-1][0].shape[1]*2\n",
    "    coms = decom[0].shape[2]\n",
    "    image_shape = (rows, cols, coms)\n",
    "    view = np.empty(image_shape, np.uint8)\n",
    "\n",
    "    # LL subband\n",
    "    view[0:decom[0].shape[0],\n",
    "         0:decom[0].shape[1]] = (decom[0].astype(np.int16) + 128).astype(np.uint16)\n",
    "\n",
    "    for l in range(len(decom)-1):\n",
    "\n",
    "        # LH\n",
    "        view[0:decom[l+1][0].shape[0],\n",
    "             decom[l+1][0].shape[1]:decom[l+1][0].shape[1]*2] =\\\n",
    "                (decom[l+1][0].astype(np.int16) + 128).astype(np.uint16)\n",
    "\n",
    "        # HL\n",
    "        view[decom[l+1][1].shape[0]:decom[l+1][1].shape[0]*2,\n",
    "             0:decom[l+1][1].shape[1]] =\\\n",
    "                (decom[l+1][1].astype(np.int16) + 128).astype(np.uint16)\n",
    "\n",
    "        # HH\n",
    "        view[decom[l+1][2].shape[0]:decom[l+1][2].shape[0]*2,\n",
    "             decom[l+1][2].shape[1]:decom[l+1][2].shape[1]*2] =\\\n",
    "                (decom[l+1][2].astype(np.int16) + 128).astype(np.uint16)\n",
    "            \n",
    "    return image_3.write(view, prefix, image_number)\n",
    "\n",
    "def read_compact_decomposition(prefix, image_number, N_levels):\n",
    "    view = image.read(prefix, image_number)\n",
    "    wavelet = pywt.Wavelet(\"Haar\")\n",
    "    decom = DWT.analyze(np.zeros_like(view), wavelet, N_levels)\n",
    "    \n",
    "    # LL subband\n",
    "    decom[0][...] = view[0:decom[0].shape[0],\n",
    "                         0:decom[0].shape[1]] - 32768\n",
    "    \n",
    "    for l in range(len(N_levels)):\n",
    "        \n",
    "        # LH\n",
    "        decom[l+1][0] =\\\n",
    "            view[0:decom[l+1][0].shape[0],\n",
    "                 decom[l+1][0].shape[1]:decom[l+1][0].shape[1]*2] - 32668\n",
    "            \n",
    "        # HL\n",
    "        decom[l+1][1] =\\\n",
    "            view[decom[l+1][1].shape[0]:decom[l+1][1].shape[0]*2,\n",
    "                 0:decom[l+1][1].shape[1]] - 32768\n",
    "            \n",
    "        # HH\n",
    "        decom[l+1][2] =\\\n",
    "            view[decom[l+1][2].shape[0]:decom[l+1][2].shape[0]*2,\n",
    "                 decom[l+1][2].shape[1]:decom[l+1][2].shape[1]*2] - 32768\n",
    "\n",
    "    return decom\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No me borres todva (mira lo que tengo dentro)\n",
    "\n",
    "img = image_3.read(test_image)\n",
    "YUV_img = YUV.from_RGB(img.astype(np.int16))\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "DWT_RDO = []\n",
    "# Initially all the quantization steps structure are \"infinite\"=10^4.\n",
    "Q_steps_pattern = 3*[10**4] # There are 3 color components\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            Q_steps_pattern.append(10**4)\n",
    "for s in progression_of_deltas:\n",
    "    decom_8b = to_8bits(decom)\n",
    "    LL_8b = decom_8b[0]\n",
    "    _Q_step = compute_Q_step(Q_step, N_levels)\n",
    "    LL_8b_k = Q.quantize(LL_8b, _Q_step) # Baybe bettter Q.get_indexes()\n",
    "    decom_8b_k = [(LL_8b_k + 128).astype(np.uint8)]\n",
    "    LL_8b_dQ = Q.dequantize(LL_8b_k, _Q_step) # Q.get_signal()\n",
    "    decom_8b_dQ = [LL_8b_dQ]\n",
    "    sbc_counter = 0\n",
    "    level = N_levels - 1\n",
    "    for sr_8b in decom_8b[1:]: # sr = spatial_resolution\n",
    "        sr_8b_k = []\n",
    "        sr_8b_dQ = []\n",
    "        for sb_8b in sr_8b: # sb = subband\n",
    "            _Q_step = compute_Q_step(Q_step, level)\n",
    "            sb_8b_k = Q.quantize(sb_8b, _Q_step)\n",
    "            sb_8b_dQ = Q.dequantize(sb_8b_k, _Q_step)\n",
    "            sr_8b_k.append((sb_8b_k + 128).astype(np.uint8))\n",
    "            sr_8b_dQ.append(sb_8b_dQ)\n",
    "            sbc_counter += 1\n",
    "        decom_8b_k.append(tuple(sr_8b_k))\n",
    "        decom_8b_dQ.append(tuple(sr_8b_dQ))\n",
    "        level -= 1\n",
    "    BPP = (DWT.write_glued(decom_8b_k, f\"/tmp/constant_{Q_step}_\", 0)[0]*8)/YUV_img.size\n",
    "    decom_dQ = to_16bits(decom_8b_dQ)\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "    img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"Q_step={Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "    DWT_RDO.append((BPP, RMSE))\n",
    "    #image_3.show(img_dQ.astype(np.uint8), f\"Q_step={Q_step} BPP={BPP:3.2f} RMSE={RMSE:4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ___estimate_codestream_len(x, prefix):\n",
    "    empty_x = np.zeros_like(x)\n",
    "    real_BPP = image_1.write(x.astype(np.uint8), prefix)\n",
    "    empty_BPP = image_1.write(empty_x.astype(np.uint8), prefix)\n",
    "    return real_BPP - empty_BPP\n",
    "    #return information.entropy(x.astype(np.int16).flatten())*x.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 0-slopes\n",
    "In each subband-component, remove those zero contributions to the quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_0_slopes(slopes):\n",
    "    filtered_slopes = []\n",
    "    for i in slopes:\n",
    "        if i[1]!= 0:\n",
    "            filtered_slopes.append(i)\n",
    "        else:\n",
    "            print(f\"removed {i}\")\n",
    "    return filtered_slopes\n",
    "\n",
    "filtered_slopes = []\n",
    "for i in RD_slopes:\n",
    "    filtered_slopes.append(filter_0_slopes(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove points that do not belong to the convex-hull\n",
    "Remove those points of each subband-component that do not satisfy that the slope is higher than the next point of the curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_slopes(slopes):\n",
    "    filtered_slopes = []\n",
    "    slopes_iterator = iter(slopes)\n",
    "    prev = next(slopes_iterator)\n",
    "    for curr in slopes_iterator:\n",
    "        if prev[1] < curr[1]:\n",
    "            print(f\"deleted {prev}\")\n",
    "        else:\n",
    "            filtered_slopes.append(prev)\n",
    "        prev = curr\n",
    "    filtered_slopes.append(prev)\n",
    "    return filtered_slopes\n",
    "\n",
    "filtered_slopes = []\n",
    "for i in RD_slopes:\n",
    "    filtered_slopes.append(filter_slopes(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Q_step, slope, subband-component number\")\n",
    "for _i, _j in enumerate(filtered_slopes):\n",
    "    print(_i, \"---\", _j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the slopes\n",
    "RD_slopes_without_sbc_index = []\n",
    "#RD_slopes_without_sbc_index.append([])\n",
    "for _c in range(N_components):\n",
    "    RD_slopes_without_sbc_index.append([])\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            RD_slopes_without_sbc_index.append([])\n",
    "for Q_step in range(len(Q_steps)):\n",
    "    RD_slopes_without_sbc_index[0].append(RD_slopes[0][Q_step][0:2])\n",
    "sbc_number = 3\n",
    "for sr in decom[1:]:\n",
    "    for sb in sr:\n",
    "        for _c in range(N_components):\n",
    "            for Q_step in range(len(Q_steps)):\n",
    "                RD_slopes_without_sbc_index[sbc_number].append(RD_slopes[sbc_number][Q_step][0:2])\n",
    "            sbc_number += 1\n",
    "print(RD_slopes_without_sbc_index[0])\n",
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*RD_slopes_without_sbc_index[0]), label=\"0\", marker=0)\n",
    "for sbc_number in range(10):\n",
    "    pylab.plot(*zip(*RD_slopes_without_sbc_index[sbc_number]), label=f\"{sbc_number}\", marker=sbc_number)\n",
    "pylab.title(\"Slopes of the RD curves of the subbands\")\n",
    "pylab.xlabel(\"Q_step\")\n",
    "pylab.ylabel(\"Slope\")\n",
    "plt.legend(loc=\"best\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Q_step(Q_step, level):\n",
    "    #step = int(math.ceil(Q_step * math.pow(2, N_levels)))\n",
    "    step = int(math.ceil(Q_step * math.pow(2, level)))\n",
    "    print(f\"compute_Q_step: Q_step={Q_step} level={level} step={step}\")\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_steps = [16, 8, 4, 2, 1, 0.5, 0.25, 1/8, 1/16]\n",
    "# Use \"uniform\" quantization and write_unglued()\n",
    "#img = image_3.read(test_image)\n",
    "#YUV_img = YUV.from_RGB(img.astype(np.int16) - 128)\n",
    "\n",
    "img = image_3.read(test_image).astype(np.int16)\n",
    "YUV_img = YUV.from_RGB(img)\n",
    "avgs = [np.average(YUV_img[..., c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "\n",
    "image_domain_DWT_RD_points2 = []\n",
    "for Q_step in Q_steps:\n",
    "    LL = decom[0]\n",
    "    print('LL')\n",
    "    _Q_step = compute_Q_step(Q_step, N_levels)\n",
    "    #LL_k = Q.quantize(LL, Q_step << N_levels) # Baybe bettter Q.get_indexes()\n",
    "    LL_k = Q.quantize(LL, _Q_step) # Baybe bettter Q.get_indexes()\n",
    "    #LL_k = Q.quantize(LL, Q_step) # Baybe bettter Q.get_indexes()\n",
    "    #assert (-128 <= LL_k).all() and (LL_k <= 127).all(), print(\"LL\", Q_step, np.unique(LL_k))\n",
    "    #LL_dQ = Q.dequantize(LL_k, Q_step << N_levels) # Q.get_signal()\n",
    "    LL_dQ = Q.dequantize(LL_k, _Q_step) # Q.get_signal()\n",
    "    #LL_dQ = Q.dequantize(LL_k, Q_step) # Q.get_signal()\n",
    "    if drange(LL_k) < 256:\n",
    "        decom_k = [(LL_k + 128).astype(np.uint8)]\n",
    "    else:\n",
    "        decom_k = [(LL_k + 32768).astype(np.uint16)]\n",
    "    decom_dQ = [LL_dQ]\n",
    "    #dist = distortion.RMSE(LL, LL_dQ)\n",
    "    #RMSE = (dist * LL.size)/x.size\n",
    "    #print(gains[0], dist, gains[0] * dist, RMSE)\n",
    "    #for i in range(4):\n",
    "    #    for j in range(4):\n",
    "    #        print(LL[i, j], LL_dQ[i, j])\n",
    "    sbc_counter = 0\n",
    "    levels_counter = N_levels - 1\n",
    "    for sr in decom[1:]: # sr = spatial_resolution\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr: # sb = subband\n",
    "            #print(RMSE)\n",
    "            #sb_k = Q.quantize(sb, Q_step << levels_counter)\n",
    "            print(f\"levels_counter={levels_counter}\")\n",
    "            _Q_step = compute_Q_step(Q_step, levels_counter)\n",
    "            sb_k = Q.quantize(sb, _Q_step)\n",
    "            #sb_k = Q.quantize(sb, Q_step)\n",
    "            #assert (-128 <= sb_k).all() and (sb_k <= 127).all(), print(sbc_counter, np.unique(sb_k))\n",
    "            #sb_dQ = Q.dequantize(sb_k, Q_step << levels_counter)\n",
    "            sb_dQ = Q.dequantize(sb_k, _Q_step)\n",
    "            #sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "            if drange(sb_k) < 256:\n",
    "                sr_k.append((sb_k + 128).astype(np.uint8))\n",
    "            else:\n",
    "                sr_k.append((sb_k + 32768).astype(np.uint16))\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            #dist = distortion.RMSE(sb, sb_dQ)\n",
    "            #print(gains[counter], dist, gains[counter] * dist, RMSE)\n",
    "            #MSE += (dist * sb.size)/x.size\n",
    "            sbc_counter += 1\n",
    "        decom_k.append(tuple(sr_k))\n",
    "        decom_dQ.append(tuple(sr_dQ))\n",
    "        levels_counter += 1\n",
    "    #subbands_info(decom_dQ)\n",
    "    #BPP = (write_compact_decomposition(decom_k, f\"/tmp/constant_{Q_step}_\", 0)*8)/YUV_img.size\n",
    "    #shifted_decom_k = DWT.add(decom_k, 128)\n",
    "    #shifted_decom_k = DWT.set_type(decom_k, np.uint8)\n",
    "    #BPP = (DWT.write(decom_k, f\"/tmp/constant_{Q_step}_\", 0)[0]*8)/YUV_img.size\n",
    "    BPP = (DWT.write_unglued(decom_k, f\"/tmp/constant_{Q_step}_\", 0)[0]*8)/YUV_img.size\n",
    "    YUV_img_dQ = DWT.synthesize(decom_dQ, wavelet, N_levels)\n",
    "\n",
    "    for c in range(3):\n",
    "        YUV_img_dQ[..., c] += int(avgs[c])\n",
    "    img_dQ = YUV.to_RGB(YUV_img_dQ)\n",
    "    img_dQ = np.clip(img_dQ, a_min=0, a_max=255).astype(np.uint8)\n",
    "\n",
    "    #img_dQ = np.clip(YUV.to_RGB(YUV_img_dQ), a_min=-128, a_max=127) + 128\n",
    "    #img_dQ = YUV.to_RGB(YUV_img_dQ) + 128\n",
    "    #clipped_img_dQ = np.clip(img_dQ, a_min=0, a_max=255)\n",
    "    #RMSE = distortion.RMSE(img, clipped_img_dQ)\n",
    "    RMSE = distortion.RMSE(img, img_dQ)\n",
    "    print(f\"_Q_step={_Q_step} BPP={BPP} RMSE={RMSE}\")\n",
    "    image_domain_DWT_RD_points2.append((BPP, RMSE))\n",
    "    image_3.show(img_dQ.astype(np.uint8), f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lossy compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = image_3.read(test_image).astype(np.int16)\n",
    "YUV_img = YUV.from_RGB(img)\n",
    "avgs = [np.average(YUV_img[...,c]) for c in range(3)]\n",
    "print(f\"avgs={avgs}\")\n",
    "for c in range(3):\n",
    "    YUV_img[..., c] -= int(avgs[c])\n",
    "decom = DWT.analyze(YUV_img, wavelet, N_levels)\n",
    "decom8 = _8bits_me(decom)\n",
    "decom8_ = DWT.add(decom8, 128)\n",
    "decom8__ = DWT.set_type(decom8_, np.uint8)\n",
    "output_len, slices = DWT.write_glued(decom8__, \"/tmp/lossless\", 0)\n",
    "_decom8 = DWT.read_glued(slices, \"/tmp/lossless\", 0)\n",
    "_decom8 = inverse_8bits_me(_decom8)\n",
    "_decom8 = DWT.add(_decom8, -128)\n",
    "_YUV_img8 = DWT.synthesize(_decom8, wavelet, N_levels)\n",
    "for c in range(3):\n",
    "    _YUV_img[..., c] += int(avgs[c])\n",
    "_img = YUV.to_RGB(_YUV_img).astype(np.uint8)\n",
    "image_3.show(_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_3.show(img - _img + 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_3.show(image_3.normalize(img - _img + 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbands_info(decom8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization steps\n",
    "\n",
    "The high dynamic range of the wavelet coefficients dificults the use 8-bit RGB PNG encoding, which is more compact that the 16-bit version. At this point, we have basically two alternatives:\n",
    "1. Use a set of high enough quantization steps to keep the quantization indexes into 8 bits. However, notice that this probably is going to ignore most of the information of the high-frequency subbands because the amplitude of their coefficients are smaller than the smaller quantization step.\n",
    "2. If the quality provided by the smaller quantization step is not enough, the unencoded (least significant) bit-planes of the coefficients can be compressed in a second 8-bit PNG image. TO-DO.\n",
    "3. Check the dynamic range of the quantization idexes and if is larger than [-128, 127] use 16 bpps.\n",
    "\n",
    "Notice that the smaller quantization step dependens on several factors:\n",
    "1. The wavelet.\n",
    "2. The number of levels.\n",
    "3. The image content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q_steps = [4096, 2048, 1024, 512, 256, 128]\n",
    "#Q_steps = [256, 128, 64, 32, 16]\n",
    "#Q_steps = [64, 32, 16]\n",
    "Q_steps = [32, 16, 8, 4, 2, 1, 0.5]\n",
    "#Q_steps = [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform quantization vs optimal quantization\n",
    "\n",
    "As we did with the DCT, let's compare both types of quantization in the RD space. Steps:\n",
    "\n",
    "1. Compute the RD slope of each subband for a set of quantization steps. For this we will suppose that the subbands are independent (the DWT is orthogonal), measuring the distortion in the wavelet domain.\n",
    "2. Sort the slopes. This will determine the optimal progression of quantization steps (which subband to incorporate more data to the code-stream, progressively).\n",
    "3. Compute the distortion in the image domain for each bit-rate. Notice that this information should match with the privided by the step 1 (measuring the distortion in the wavelet domain). However, we prefer to computate the distortion in the image domain because the transform does not need to be orthogonal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Read the image, move to the YUV domain, and compute the DWT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = read_image(test_image)\n",
    "x = YUV.from_RGB(xx.astype(np.int16) - 128)\n",
    "y = DWT.analyze(x, wavelet, N_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each subband, we populate:\n",
    "1. A list of RD points, and\n",
    "2. A list of RD slopes with these points, indicanting also the corresponding quantization step and subband.\n",
    "\n",
    "Remember that we have a RD point for each quantization step for each subband. The first dimension of these lists is indexed the subband, and the second dimension is indexed by the quantization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BPP=0, the RMSE is the energy of the subband. No slope can be computed for the first point.\n",
    "RD_points = [[(0, information.energy(y[0]) / y[0].size)]] # Work with RMSE's that are average distortions\n",
    "RD_slopes = [[]]\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        sb_avg_energy = information.energy(sb) / sb.size\n",
    "        # The first point of each RD curve has a maximum distortion equal\n",
    "        # to the energy of the subband and a rate = 0\n",
    "        RD_points.append([(0, sb_avg_energy)])\n",
    "        RD_slopes.append([])\n",
    "\n",
    "for i,j in enumerate(RD_points):\n",
    "    print(i,j)\n",
    "    \n",
    "for i,j in enumerate(RD_slopes):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now populate the rest of points of each subband\n",
    "\n",
    "# Subband LL\n",
    "sb_number = 0\n",
    "sb = y[0]\n",
    "Q_step_number = 0\n",
    "for Q_step in Q_steps:\n",
    "    print(Q_steps)\n",
    "    sb_k = Q.quantize(sb, Q_step)\n",
    "    sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "    sb_RMSE = distortion.RMSE(sb, sb_dQ)\n",
    "    sb_BPP = information.PNG_BPP((sb_k.astype(np.int32) + 32768).astype(np.uint16), \"/tmp/BPP_\")[0]\n",
    "    #sb_BPP = information.entropy(sb_k.astype(np.int16).flatten())\n",
    "    RD_points[sb_number].append((sb_BPP, sb_RMSE))\n",
    "    delta_BPP = sb_BPP - RD_points[sb_number][Q_step_number][0]\n",
    "    delta_RMSE = RD_points[sb_number][Q_step_number][1] - sb_RMSE\n",
    "    if delta_BPP > 0:\n",
    "        slope = delta_RMSE/delta_BPP\n",
    "    else:\n",
    "        slope = 0\n",
    "    RD_slopes[sb_number].append((Q_step, slope, (sb_number)))\n",
    "    Q_step_number += 1\n",
    "\n",
    "print(N_levels)\n",
    "    \n",
    "for i,j in enumerate(RD_points):\n",
    "    print(i, \"---\", j)\n",
    "    \n",
    "for i,j in enumerate(RD_slopes):\n",
    "    print(i, \"---\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_number = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        Q_step_number = 0\n",
    "        for Q_step in Q_steps:\n",
    "            sb_k = Q.quantize(sb, Q_step)\n",
    "            sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "            sb_RMSE = distortion.RMSE(sb, sb_dQ)\n",
    "            sb_BPP = information.PNG_BPP((sb_k.astype(np.int32) + 32768).astype(np.uint16), \"/tmp/BPP_\")[0]\n",
    "            #sb_BPP = information.entropy(sb_k.astype(np.int16).flatten())\n",
    "            RD_points[sb_number].append((sb_BPP, sb_RMSE))\n",
    "            delta_BPP = sb_BPP - RD_points[sb_number][Q_step_number][0]\n",
    "            delta_RMSE = RD_points[sb_number][Q_step_number][1] - sb_RMSE\n",
    "            if delta_BPP > 0:\n",
    "                slope = delta_RMSE/delta_BPP\n",
    "            else:\n",
    "                slope = 9^9\n",
    "            print(sb_number, len(y))\n",
    "            RD_slopes[sb_number].append((Q_step, slope, (sb_number)))\n",
    "            Q_step_number += 1\n",
    "        sb_number += 1\n",
    "        \n",
    "for i,j in enumerate(RD_points):\n",
    "    print(i, \"---\", j)\n",
    "    \n",
    "for i,j in enumerate(RD_slopes):\n",
    "    print(i, \"---\", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_points[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_points[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Bits/Pixel\")\n",
    "    pylab.ylabel(\"RMSE\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_points[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_points[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Bits/Pixel\")\n",
    "    pylab.ylabel(\"RMSE\")\n",
    "    pylab.yscale(\"log\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_slopes_without_sb_index = []\n",
    "RD_slopes_without_sb_index.append([])\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        RD_slopes_without_sb_index.append([])\n",
    "for Q_step in range(len(Q_steps)):\n",
    "    RD_slopes_without_sb_index[0].append(RD_slopes[0][Q_step][0:2])\n",
    "sb_number = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        for Q_step in range(len(Q_steps)):\n",
    "            RD_slopes_without_sb_index[sb_number].append(RD_slopes[sb_number][Q_step][0:2])\n",
    "        sb_number += 1\n",
    "print(RD_slopes_without_sb_index[0])\n",
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_slopes_without_sb_index[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_slopes_without_sb_index[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"Slopes of the RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Q_step\")\n",
    "    pylab.ylabel(\"Slope\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sb_number < 12:\n",
    "    pylab.figure(dpi=150)\n",
    "    pylab.plot(*zip(*RD_slopes_without_sb_index[0]), label=\"0\", marker=0)\n",
    "    sb_number = 1\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            pylab.plot(*zip(*RD_slopes_without_sb_index[sb_number]), label=f\"{sb_number}\", marker=sb_number)\n",
    "            sb_number += 1\n",
    "    pylab.title(\"Slopes of the RD curves of the subbands\")\n",
    "    pylab.xlabel(\"Q_step\")\n",
    "    pylab.ylabel(\"Slope\")\n",
    "    pylab.yscale(\"log\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the slopes of the curves are quite similar, but the LL subband is somewhat steeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_list = []\n",
    "for Q_step in range(len(Q_steps)):\n",
    "    single_list.append(tuple(RD_slopes[0][Q_step]))\n",
    "sb_number = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        for Q_step in range(len(Q_steps)):\n",
    "            single_list.append(tuple(RD_slopes[sb_number][Q_step]))\n",
    "        sb_number += 1\n",
    "sorted_slopes = sorted(single_list, key=lambda x: x[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(decomposition, Q_steps):\n",
    "    #print(Q_steps)\n",
    "    LL = decomposition[0]\n",
    "    LL_k = Q.quantize(LL, Q_steps[0])\n",
    "    decomposition_k = [LL_k]\n",
    "    sb_number = 1\n",
    "    for sr in decomposition[1:]:\n",
    "        sr_k = []\n",
    "        for sb in sr:\n",
    "            #print(sb_number)\n",
    "            sb_k = Q.quantize(sb, Q_steps[sb_number])\n",
    "            sr_k.append(sb_k)\n",
    "            sb_number += 1\n",
    "        decomposition_k.append(tuple(sr_k))\n",
    "    return decomposition_k\n",
    "\n",
    "def dequantize(decomposition_k, Q_steps):\n",
    "    LL_k = decomposition_k[0]\n",
    "    LL_dQ = Q.dequantize(LL_k, Q_steps[0])\n",
    "    decomposition_dQ = [LL_dQ]\n",
    "    sb_number = 1\n",
    "    for sr_k in decomposition_k[1:]:\n",
    "        sr_dQ = []\n",
    "        for sb_k in sr_k:\n",
    "            sb_dQ = Q.dequantize(sb_k, Q_steps[sb_number])\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            sb_number += 1\n",
    "        decomposition_dQ.append(tuple(sr_dQ))\n",
    "    return decomposition_dQ\n",
    "\n",
    "def resolution_level(sb_number):\n",
    "    '''Resolution level in decomposition.'''\n",
    "    if sb_number > 0:\n",
    "        return ((sb_number - 1) // 3) + 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def subband_index(sb_number):\n",
    "    '''Subband index in resolution level.'''\n",
    "    if sb_number > 0:\n",
    "        return (sb_number % 3) - 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimal_RD_points = []\n",
    "#y_prog = DWT.analyze(np.zeros_like(x), wavelet, N_levels)\n",
    "#print(len(y_prog))\n",
    "Q_steps_by_subband = [9**9]\n",
    "#for sr in y_prog[1:]:\n",
    "for sr in y[1:]:\n",
    "    #print(len(sr))\n",
    "    for sb in sr:\n",
    "        Q_steps_by_subband.append(9**9)\n",
    "#print(Q_steps_by_subband)\n",
    "slope_index = 0\n",
    "for s in sorted_slopes:\n",
    "    sb_number = s[2]\n",
    "    #print(\"sb_number\", sb_number)\n",
    "    Q_steps_by_subband[sb_number] = s[0]\n",
    "    #print(sb_number, Q_steps_by_subband[sb_number])\n",
    "    #y_prog[resolution_level(sb_number)][subband_index(sb_number)] = y[resolution_level(sb_number)][subband_index(sb_number)]\n",
    "    #y_k = quantize(y_prog, Q_steps_by_subband)\n",
    "    y_k = quantize(y, Q_steps_by_subband)\n",
    "    BPP = (write_compact_decomposition(y_k, f\"/tmp/optimal_{slope_index}_\", 0)*8)/xx.size\n",
    "    #BPP = entropy(y_k)\n",
    "    slope_index += 1\n",
    "    y_dQ = dequantize(y_k, Q_steps_by_subband)\n",
    "    z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "    zz_dQ = np.clip(YUV.to_RGB(z_dQ), a_min=-128, a_max=127) + 128\n",
    "    RMSE = distortion.RMSE(xx, zz_dQ)\n",
    "    print(f\"{Q_steps_by_subband} {BPP} {RMSE}\")\n",
    "    optimal_RD_points.append((BPP, RMSE))\n",
    "    #image_3.show_RGB_image(zz_dQ, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_RD_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*DWT_points), label=\"Uniform quantization\")\n",
    "pylab.plot(*zip(*optimal_RD_points), label=\"Optimal quantization\")\n",
    "#pylab.plot(*zip(*JPEG_RD_points), label=\"JPEG\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"RMSE\")\n",
    "plt.legend(loc=\"best\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTE PASO NO ES NECESARIO: Compute the average energy of the image and the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(decomposition):\n",
    "    accumulated_energy = information.energy(decomposition[0])\n",
    "    for sr in y[1:]:\n",
    "        for sb in sr:\n",
    "            accumulated_energy += information.energy(sb)\n",
    "    return accumulated_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = read_image(test_image).astype(np.int16) - 128\n",
    "#xx = np.full(shape=(512, 512, 3), fill_value=100) - 128\n",
    "x = YUV.from_RGB(xx)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "image_energy = information.average_energy(x)\n",
    "print(image_energy)\n",
    "print(energy(y)/x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform gains\n",
    "\n",
    "This information measures whether the transform amplifies or attenuates the signal. If the forward transform amplifies the signal, the energy of the decomposition will be larger than the energy of the original signal, and viceversa. The same idea can be applied to the inverse transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.full(shape=(512, 512, 3), fill_value=1)\n",
    "x_energy = information.energy(x)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "decom_energy = information.energy(y[0])\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        decom_energy += information.energy(sb)\n",
    "z_energy = information.energy(z)\n",
    "print(wavelet)\n",
    "print(\"Energy of the original image:\", x_energy)\n",
    "print(\"Energy of the decomposition:\", decom_energy)\n",
    "print(\"Energy of the reconstucted image:\", z_energy)\n",
    "print(\"Average energy of the original image\", x_energy / x.size)\n",
    "print(\"Average energy of the decomposition:\", decom_energy / x.size)\n",
    "print(\"Average energy of the reconstructed image:\", z_energy / x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, the transform is energy preserving, which means that we the distortion generated by quantization is the same in the image and the wavelet domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RD performance considering (and not) the subband gains\n",
    "\n",
    "We compute the RD cuve of using scalar quantization when:\n",
    "1. All subbands are quantized using the same quantization step.\n",
    "2. The quantization step used in a subband is divided by the subband gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = read_image(test_image).astype(np.int16) - 128\n",
    "x = YUV.from_RGB(xx)\n",
    "\n",
    "constant_Q_points = []\n",
    "for Q_step in Q_steps:\n",
    "    y = DWT.analyze(x, wavelet, N_levels)\n",
    "    LL = y[0]\n",
    "    LL_k = Q.quantize(LL, Q_step)\n",
    "    y_k = [LL_k]\n",
    "    LL_dQ = Q.dequantize(LL_k, Q_step)\n",
    "    y_dQ = [LL_dQ]\n",
    "    for sr in y[1:]:\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr:\n",
    "            sb_k = Q.quantize(sb, Q_step)\n",
    "            sr_k.append(sb_k)\n",
    "            sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "            sr_dQ.append(sb_dQ)\n",
    "        y_k.append(tuple(sr_k))\n",
    "        y_dQ.append(tuple(sr_dQ))\n",
    "    BPP = (write_compact_decomposition(y_k, f\"/tmp/constant_{Q_step}\", 0)*8)/x.size\n",
    "    z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "    zz_dQ = np.clip(YUV.to_RGB(z_dQ), a_min=-128, a_max=127)\n",
    "    MSE = distortion.MSE(xx, zz_dQ)\n",
    "    print(f\"{Q_step} {BPP} {MSE}\")\n",
    "    constant_Q_points.append((BPP, MSE))\n",
    "    #image_3.show_RGB_image(zz_dQ + 128, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose that the slope of the subband is proportional to the subband gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xx = read_image(test_image).astype(np.int16) - 128\n",
    "x = YUV.from_RGB(xx)\n",
    "\n",
    "relative_gains = [gain/gains[-1] for gain in gains]\n",
    "print(relative_gains)\n",
    "gains_Q_points = []\n",
    "for Q_step in Q_steps:\n",
    "    y = DWT.analyze(x, wavelet, N_levels)[::-1]\n",
    "    counter = len(y) - 1\n",
    "    for sr in y[:-1]:\n",
    "        sr_k = []\n",
    "        sr_dQ = []\n",
    "        for sb in sr:\n",
    "            _Q_step = Q_step / relative_gains[counter]\n",
    "            print(\"Q_step =\",_Q_step)\n",
    "            sb_k = Q.quantize(sb, _Q_step)\n",
    "            sr_k.append(sb_k)\n",
    "            sb_dQ = Q.dequantize(sb_k, _Q_step)\n",
    "            sr_dQ.append(sb_dQ)\n",
    "            counter -= 1\n",
    "        y_k.append(tuple(sr_k))\n",
    "        y_dQ.append(tuple(sr_dQ))\n",
    "    LL = y[-1]\n",
    "    _Q_step = Q_step / relative_gains[0]\n",
    "    print(_Q_step)\n",
    "    LL_k = Q.quantize(LL, _Q_step)\n",
    "    y_k = [LL_k]\n",
    "    LL_dQ = Q.dequantize(LL_k, _Q_step)\n",
    "    y_dQ = [LL_dQ]\n",
    "    BPP = (write_compact_decomposition(y_k, f\"/tmp/gains_{Q_step}\", 0)*8)/x.size\n",
    "    z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "    zz_dQ = np.clip(YUV.to_RGB(z_dQ), a_min=-128, a_max=127)\n",
    "    MSE = distortion.MSE(xx, zz_dQ)\n",
    "    print(f\"{Q_step} {BPP} {MSE}\")\n",
    "    gains_Q_points.append((BPP, MSE))\n",
    "    image_3.show_RGB_image(zz_dQ + 128, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.figure(dpi=150)\n",
    "pylab.plot(*zip(*constant_Q_points), label=f\"Constant Q\")\n",
    "pylab.plot(*zip(*gains_Q_points), label=f\"Gains Q\")\n",
    "pylab.title(test_image)\n",
    "pylab.xlabel(\"Bits/Pixel\")\n",
    "pylab.ylabel(\"MSE\")\n",
    "plt.legend(loc='upper right')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quantization progression\n",
    "\n",
    "The previous quantization is not (usually) optimal, because the RD constribution of each subband is not constant.\n",
    "Let's use now a different quantization step for each subband that operates (approximately) at the same RD slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example of uniform quantization\n",
    "\n",
    "We will measure also the distortion in both domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_step = 128\n",
    "x = read_image(test_image).astype(np.int16) #- 128\n",
    "#x = YUV.from_RGB(xx)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "\n",
    "LL = y[0]\n",
    "LL_k = Q.quantize(LL, Q_step)\n",
    "LL_dQ = Q.dequantize(LL_k, Q_step)\n",
    "dist = distortion.MSE(LL, LL_dQ)\n",
    "subband_ratio = LL.size / x.size\n",
    "print(subband_ratio)\n",
    "MSE_wavelet_domain = dist * subband_ratio #* gains[0]\n",
    "counter = 1\n",
    "y_dQ = [LL_dQ]\n",
    "for sr in y[1:]:\n",
    "    sr_dQ = []\n",
    "    for sb in sr:\n",
    "        sb_k = Q.quantize(sb, Q_step)\n",
    "        sb_dQ = Q.dequantize(sb_k, Q_step)\n",
    "        sr_dQ.append(sb_dQ)\n",
    "        dist = distortion.MSE(sb, sb_dQ)\n",
    "        subband_ratio = sb.size / x.size\n",
    "        print(subband_ratio)\n",
    "        MSE_wavelet_domain += dist * subband_ratio #* gains[counter]\n",
    "        counter += 1\n",
    "    y_dQ.append(tuple(sr_dQ))\n",
    "\n",
    "z_dQ = DWT.synthesize(y_dQ, wavelet, N_levels)\n",
    "cz_dQ = np.clip(z_dQ, a_min=0, a_max=255)\n",
    "#zz_dQ = np.clip( YUV.to_RGB(z_dQ) + 128, a_min=0, a_max=255)\n",
    "#zz_dQ = YUV.to_RGB(z_dQ) #+ 128\n",
    "#print(\"Distortion in the image domain:\", distortion.MSE(xx + 128, zz_dQ))\n",
    "print(\"Distortion in the image domain:\", distortion.MSE(x, cz_dQ))\n",
    "print(\"Distortion in the wavelet domain:\", MSE_wavelet_domain)\n",
    "image_3.show_RGB_image_3(cz_dQ, f\"Reconstructed image (Q_step={Q_step})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quantization progression\n",
    "\n",
    "The previous quantization is not (usually) optimal, because the RD constribution of each subband is not constant.\n",
    "Let's use now a different quantization step for each subband that operates (approximately) at the same RD slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An orthogonality test\n",
    "\n",
    "Orthogonality is necessary to avoid that the quantization error generated in a subband does not affect to the rest of subband. This will speed up the RD optimization because the distortion can be measured in the DWT domain.\n",
    "\n",
    "This orthogonality test does:\n",
    "1. Compute the DWT of an image.\n",
    "2. Set to zero all the subbands except one.\n",
    "3. Compute the inverse DWT.\n",
    "4. Compute the DWT again of the previous reconstruction.\n",
    "5. Test if the decomposition matches the one generated in the step 2.  If matches (with some maximum error), the transform is orthogonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "subband_to_keep = 5\n",
    "if subband_to_keep > DWT._N_levels:\n",
    "    print(\"No way, Jos\")\n",
    "y[0][...] = 0.0\n",
    "counter = 0\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        if counter != subband_to_keep:\n",
    "            sb[...] = 0.0\n",
    "        counter += 1\n",
    "z = DWT.synthesize(y, wavelet, N_levels)\n",
    "#image_3.show_RGB_image(z, \"Reconstructed image\")\n",
    "y2 = DWT.analyze(z, wavelet, N_levels)\n",
    "counter = 0\n",
    "orthogonal = True\n",
    "for sr, sr2 in zip(y[1:], y2[1:]):\n",
    "    for sb, sb2 in zip(sr, sr2):\n",
    "        #print((sb == sb2).allclose())\n",
    "        if not np.allclose(sb, sb2):\n",
    "            orthogonal = False\n",
    "        #if counter == subband_to_keep:\n",
    "        #    image_3.show_RGB_image(sb)\n",
    "        #    image_3.show_RGB_image(sb2)\n",
    "        counter += 1\n",
    "print(\"Orthogonal:\", orthogonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to know if the transform is orthogonal is compute the quantization distortion in the wavelet domain and see if it is the same than the distortion in the image domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal quantization progression\n",
    "\n",
    "The previous quantization is not (usually) optimal, because the RD constribution of each subband is not constant.\n",
    "Let's use now a different quantization step for each subband that operates (approximately) at the same RD slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information is important to known if the transform is unitary or not (usually, biorthogonal transforms are not unitary, i.e., the energy of the decomposition is different to (usually larger than) the energy of the image). Notice that if the transform is not unitary, the distortion is measured differently in the image and the transform domain. For example, is the gain is larger than 1, then overall distortion should be divided by the gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_image(test_image)\n",
    "#x = YUV.from_RGB(xx)\n",
    "y = DWT.analyze(x, wavelet, N_levels)\n",
    "image_energy = distortion.energy(x)\n",
    "image_average_energy = image_energy / x.size\n",
    "print(\"Image average energy:\", image_average_energy)\n",
    "#decom_average_energy = distortion.average_energy(y[0])*y[0].size/x.size\n",
    "decom_energy = distortion.energy(y[0])\n",
    "counter = 1\n",
    "for sr in y[1:]:\n",
    "    for sb in sr:\n",
    "        #decom_energy += distortion.average_energy(sb)*sb.size/x.size\n",
    "        decom_energy += distortion.energy(sb)\n",
    "        counter += 1\n",
    "print(\"Decomposition energy\", decom_energy)\n",
    "decom_average_energy = decom_energy / x.size\n",
    "print(\"Decomposition average energy\", decom_average_energy)\n",
    "forward_transform_gain = decom_energy/image_energy\n",
    "print(\"Forward transform gain:\", forward_transform_gain)\n",
    "print(\"The transform is\", end=' ')\n",
    "try:\n",
    "    np.testing.assert_almost_equal(forward_transform_gain, 1.0)\n",
    "except AssertionError:\n",
    "    print(\"not unitary\")\n",
    "else:\n",
    "    print(\"unitary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image and move to the YCoCg domain.\n",
    "x = image_3.read(test_image)\n",
    "xx = YUV.from_RGB(x.astype(np.int16) - 128)\n",
    "#xx = YUV.from_RGB(x.astype(np.int16))\n",
    "yy = DWT.analyze(xx, wavelet, N_levels)\n",
    "zz_dQ = DWT.synthesize(yy, wavelet, N_levels)\n",
    "z_dQ = np.clip(YUV.to_RGB(zz_dQ) + 128, a_min=0, a_max=255).astype(np.uint8)\n",
    "#z_dQ = YUV.to_RGB(zz_dQ).astype(np.uint8)\n",
    "image_3.show(z_dQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing `DWT.analyze_step()` and `DCT.synthesize_step()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image_3.read(test_image)\n",
    "image_3.show(x, title=\"Original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, H = DWT.analyze_step(x, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_3.show(image_3.normalize(L), \"LL DWT domain\")\n",
    "subbands = (\"LH\", \"HL\", \"HH\")\n",
    "for i, sb in enumerate(subbands):\n",
    "    image_3.show(image_3.normalize(H[i]), f\"{sb} DWT domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = DWT.synthesize_step(L, H, wavelet).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = x - z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_3.show(image_3.normalize(r), f\"DWT finite precission error N_DWT_levels={N_levels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DWT is not fully reversible, but it is almost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_3.show(z, \"Reconstructed image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGB_image_compression:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWT_image_compression:\n",
    "    def encode_RGB_image(img, Q_step):\n",
    "        YUV_img = YUV.from_RGB(img.astype(np.int16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
